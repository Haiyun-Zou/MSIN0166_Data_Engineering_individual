{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54cc2ca",
   "metadata": {},
   "source": [
    "<h1><center>MSIN0166 Data Engineering Individual Assignment</h1>\n",
    "    <h2><center>Due: 26th April 2022</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2166dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import dvc.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad2ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043a07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the display option\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5da320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "Hit:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:3 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:4 https://packages.cloud.google.com/apt cloud-sdk InRelease [6,751 B]      \n",
      "Get:5 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/multiverse Sources [19.7 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \n",
      "Get:7 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main Sources [660 kB]\n",
      "Get:8 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe Sources [602 kB]\n",
      "Get:9 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/restricted Sources [31.4 kB]\n",
      "Get:10 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [941 kB]\n",
      "Get:11 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,165 kB]\n",
      "Get:12 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
      "Get:13 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
      "Get:14 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports/main Sources [6,591 B]\n",
      "Get:15 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports/universe Sources [7,129 B]\n",
      "Get:16 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
      "Get:17 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
      "Get:18 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [249 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse Sources [8,784 B]\n",
      "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main Sources [339 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe Sources [368 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted Sources [28.0 kB]\n",
      "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,496 kB]\n",
      "Get:25 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [907 kB]\n",
      "Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,728 kB]\n",
      "Fetched 14.2 MB in 1s (10.1 MB/s)                              \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Calculating upgrade... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  python3-crcmod\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following packages will be upgraded:\n",
      "  apt apt-transport-https apt-utils base-files bash bind9-host binutils\n",
      "  binutils-common binutils-x86-64-linux-gnu ca-certificates curl\n",
      "  distro-info-data dnsutils git git-man google-cloud-sdk gzip libapt-inst2.0\n",
      "  libapt-pkg5.0 libasound2 libasound2-data libbind9-160 libbinutils libc-bin\n",
      "  libc-dev-bin libc6 libc6-dev libcurl3-gnutls libcurl4 libdns1100 libexpat1\n",
      "  libexpat1-dev libgcrypt20 libgd3 libglib2.0-0 libgnutls30 libicu60 libirs160\n",
      "  libisc169 libisccc160 libisccfg160 libkeyutils1 liblwres160 liblzma5\n",
      "  libmysqlclient-dev libmysqlclient20 libpq5 libpython2.7-minimal\n",
      "  libpython2.7-stdlib libpython3.6 libpython3.6-dev libpython3.6-minimal\n",
      "  libpython3.6-stdlib libruby2.5 libsasl2-2 libsasl2-modules-db libseccomp2\n",
      "  libssl-dev libssl1.0.0 libssl1.1 libsystemd0 libudev1 libxml2 linux-libc-dev\n",
      "  locales login multiarch-support mysql-client mysql-client-5.7\n",
      "  mysql-client-core-5.7 openssh-client openssh-server openssh-sftp-server\n",
      "  openssl passwd postgresql-client-10 python-apt-common python2.7\n",
      "  python2.7-minimal python3-apt python3-software-properties python3.6\n",
      "  python3.6-dev python3.6-minimal rsync ruby2.5 software-properties-common tar\n",
      "  tzdata vim-common vim-nox vim-runtime vim-tiny xxd xz-utils zlib1g\n",
      "  zlib1g-dev\n",
      "97 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 250 MB of archives.\n",
      "After this operation, 267 MB of additional disk space will be used.\n",
      "Get:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc6-dev amd64 2.27-3ubuntu1.5 [2,587 kB]\n",
      "Get:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc-dev-bin amd64 2.27-3ubuntu1.5 [71.9 kB]\n",
      "Get:3 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 linux-libc-dev amd64 4.15.0-176.185 [986 kB]\n",
      "Get:4 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc6 amd64 2.27-3ubuntu1.5 [2,830 kB]\n",
      "Get:5 https://packages.cloud.google.com/apt cloud-sdk/main amd64 google-cloud-sdk all 382.0.0-0 [130 MB]\n",
      "Get:6 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 base-files amd64 10.1ubuntu2.11 [60.4 kB]\n",
      "Get:7 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 bash amd64 4.4.18-2ubuntu1.3 [615 kB]\n",
      "Get:8 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 gzip amd64 1.6-5ubuntu1.2 [90.3 kB]\n",
      "Get:9 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 login amd64 1:4.5-1ubuntu2.2 [308 kB]\n",
      "Get:10 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 tar amd64 1.29b-2ubuntu0.3 [234 kB]\n",
      "Get:11 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 locales all 2.27-3ubuntu1.5 [3,613 kB]\n",
      "Get:12 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libc-bin amd64 2.27-3ubuntu1.5 [638 kB]\n",
      "Get:13 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblzma5 amd64 5.2.2-1.3ubuntu0.1 [91.1 kB]\n",
      "Get:14 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsystemd0 amd64 237-3ubuntu10.53 [206 kB]\n",
      "Get:15 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libudev1 amd64 237-3ubuntu10.53 [55.6 kB]\n",
      "Get:16 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 zlib1g-dev amd64 1:1.2.11.dfsg-0ubuntu2.1 [176 kB]\n",
      "Get:17 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 zlib1g amd64 1:1.2.11.dfsg-0ubuntu2.1 [56.4 kB]\n",
      "Get:18 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libapt-pkg5.0 amd64 1.6.14 [809 kB]\n",
      "Get:19 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libapt-inst2.0 amd64 1.6.14 [57.3 kB]\n",
      "Get:20 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 apt amd64 1.6.14 [1,207 kB]\n",
      "Get:21 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 apt-utils amd64 1.6.14 [209 kB]\n",
      "Get:22 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgnutls30 amd64 3.5.18-1ubuntu1.5 [646 kB]\n",
      "Get:23 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libseccomp2 amd64 2.5.1-1ubuntu1~18.04.2 [43.0 kB]\n",
      "Get:24 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1-dev amd64 2.2.5-3ubuntu0.7 [124 kB]\n",
      "Get:25 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1 amd64 2.2.5-3ubuntu0.7 [82.6 kB]\n",
      "Get:26 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-dev amd64 3.6.9-1~18.04ubuntu1.7 [511 kB]\n",
      "Get:27 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-dev amd64 3.6.9-1~18.04ubuntu1.7 [44.9 MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:28 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6 amd64 3.6.9-1~18.04ubuntu1.7 [1,414 kB]\n",
      "Get:29 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl-dev amd64 1.1.1-1ubuntu2.1~18.04.15 [1,568 kB]\n",
      "Get:30 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl1.1 amd64 1.1.1-1ubuntu2.1~18.04.15 [1,303 kB]\n",
      "Get:31 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6 amd64 3.6.9-1~18.04ubuntu1.7 [203 kB]\n",
      "Get:32 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-stdlib amd64 3.6.9-1~18.04ubuntu1.7 [1,710 kB]\n",
      "Get:33 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-minimal amd64 3.6.9-1~18.04ubuntu1.7 [1,610 kB]\n",
      "Get:34 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-minimal amd64 3.6.9-1~18.04ubuntu1.7 [534 kB]\n",
      "Get:35 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python2.7 amd64 2.7.17-1~18.04ubuntu1.7 [248 kB]\n",
      "Get:36 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7-stdlib amd64 2.7.17-1~18.04ubuntu1.7 [1,917 kB]\n",
      "Get:37 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python2.7-minimal amd64 2.7.17-1~18.04ubuntu1.7 [1,288 kB]\n",
      "Get:38 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython2.7-minimal amd64 2.7.17-1~18.04ubuntu1.7 [335 kB]\n",
      "Get:39 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgcrypt20 amd64 1.8.1-4ubuntu1.3 [418 kB]\n",
      "Get:40 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 passwd amd64 1:4.5-1ubuntu2.2 [818 kB]\n",
      "Get:41 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.15 [614 kB]\n",
      "Get:42 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 ca-certificates all 20210119~18.04.2 [145 kB]\n",
      "Get:43 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 distro-info-data all 0.37ubuntu0.13 [4,656 B]\n",
      "Get:44 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libglib2.0-0 amd64 2.56.4-0ubuntu0.18.04.9 [1,169 kB]\n",
      "Get:45 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libicu60 amd64 60.2-3ubuntu3.2 [8,050 kB]\n",
      "Get:46 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2 amd64 2.9.4+dfsg1-6.1ubuntu1.5 [663 kB]\n",
      "Get:47 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 tzdata all 2022a-0ubuntu0.18.04 [190 kB]\n",
      "Get:48 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.11 [3,072 kB]\n",
      "Get:49 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 vim-nox amd64 2:8.0.1453-1ubuntu1.8 [1,229 kB]\n",
      "Get:50 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 vim-tiny amd64 2:8.0.1453-1ubuntu1.8 [476 kB]\n",
      "Get:51 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 vim-runtime all 2:8.0.1453-1ubuntu1.8 [5,435 kB]\n",
      "Get:52 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 xxd amd64 2:8.0.1453-1ubuntu1.8 [49.9 kB]\n",
      "Get:53 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 vim-common all 2:8.0.1453-1ubuntu1.8 [71.1 kB]\n",
      "Get:54 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 xz-utils amd64 5.2.2-1.3ubuntu0.1 [83.8 kB]\n",
      "Get:55 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libirs160 amd64 1:9.11.3+dfsg-1ubuntu1.17 [19.1 kB]\n",
      "Get:56 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 bind9-host amd64 1:9.11.3+dfsg-1ubuntu1.17 [53.5 kB]\n",
      "Get:57 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 dnsutils amd64 1:9.11.3+dfsg-1ubuntu1.17 [145 kB]\n",
      "Get:58 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbind9-160 amd64 1:9.11.3+dfsg-1ubuntu1.17 [27.6 kB]\n",
      "Get:59 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libisccfg160 amd64 1:9.11.3+dfsg-1ubuntu1.17 [48.4 kB]\n",
      "Get:60 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libisccc160 amd64 1:9.11.3+dfsg-1ubuntu1.17 [17.9 kB]\n",
      "Get:61 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdns1100 amd64 1:9.11.3+dfsg-1ubuntu1.17 [959 kB]\n",
      "Get:62 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libisc169 amd64 1:9.11.3+dfsg-1ubuntu1.17 [237 kB]\n",
      "Get:63 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblwres160 amd64 1:9.11.3+dfsg-1ubuntu1.17 [34.4 kB]\n",
      "Get:64 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkeyutils1 amd64 1.5.9-9.2ubuntu2.1 [8,764 B]\n",
      "Get:65 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl1.0.0 amd64 1.0.2n-1ubuntu5.8 [1,088 kB]\n",
      "Get:66 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 multiarch-support amd64 2.27-3ubuntu1.5 [6,960 B]\n",
      "Get:67 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-sftp-server amd64 1:7.6p1-4ubuntu0.6 [45.5 kB]\n",
      "Get:68 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-server amd64 1:7.6p1-4ubuntu0.6 [332 kB]\n",
      "Get:69 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 git-man all 1:2.17.1-1ubuntu0.10 [804 kB]\n",
      "Get:70 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl3-gnutls amd64 7.58.0-2ubuntu3.16 [218 kB]\n",
      "Get:71 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 git amd64 1:2.17.1-1ubuntu0.10 [3,923 kB]\n",
      "Get:72 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-client amd64 1:7.6p1-4ubuntu0.6 [612 kB]\n",
      "Get:73 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-apt-common all 1.6.5ubuntu0.7 [16.9 kB]\n",
      "Get:74 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-apt amd64 1.6.5ubuntu0.7 [149 kB]\n",
      "Get:75 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 rsync amd64 3.1.2-2.1ubuntu1.4 [334 kB]\n",
      "Get:76 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.14 [4,348 B]\n",
      "Get:77 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.30-21ubuntu1~18.04.7 [1,839 kB]\n",
      "Get:78 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils-common amd64 2.30-21ubuntu1~18.04.7 [197 kB]\n",
      "Get:79 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 binutils amd64 2.30-21ubuntu1~18.04.7 [3,388 B]\n",
      "Get:80 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbinutils amd64 2.30-21ubuntu1~18.04.7 [489 kB]\n",
      "Get:81 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 curl amd64 7.58.0-2ubuntu3.16 [159 kB]\n",
      "Get:82 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4 amd64 7.58.0-2ubuntu3.16 [220 kB]\n",
      "Get:83 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2 amd64 1.1.3-5ubuntu0.6 [360 kB]\n",
      "Get:84 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libasound2-data all 1.1.3-5ubuntu0.6 [38.5 kB]\n",
      "Get:85 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.5 [119 kB]\n",
      "Get:86 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmysqlclient-dev amd64 5.7.37-0ubuntu0.18.04.1 [1,019 kB]\n",
      "Get:87 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmysqlclient20 amd64 5.7.37-0ubuntu0.18.04.1 [689 kB]\n",
      "Get:88 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpq5 amd64 10.19-0ubuntu0.18.04.1 [108 kB]\n",
      "Get:89 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-modules-db amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.4 [15.0 kB]\n",
      "Get:90 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-2 amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.4 [49.2 kB]\n",
      "Get:91 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-client-core-5.7 amd64 5.7.37-0ubuntu0.18.04.1 [6,635 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:92 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-client-5.7 amd64 5.7.37-0ubuntu0.18.04.1 [1,943 kB]\n",
      "Get:93 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-client all 5.7.37-0ubuntu0.18.04.1 [9,820 B]\n",
      "Get:94 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 postgresql-client-10 amd64 10.19-0ubuntu0.18.04.1 [942 kB]\n",
      "Get:95 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 software-properties-common all 0.96.24.32.18 [10.1 kB]\n",
      "Get:96 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-software-properties all 0.96.24.32.18 [23.8 kB]\n",
      "Get:97 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.11 [48.6 kB]\n",
      "Fetched 250 MB in 2s (123 MB/s)      \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 97.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Extracting templates from packages: 100%\n",
      "Preconfiguring packages ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libc6-dev_2.27-3ubuntu1.5_amd64.deb ...\n",
      "Unpacking libc6-dev:amd64 (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Preparing to unpack .../libc-dev-bin_2.27-3ubuntu1.5_amd64.deb ...\n",
      "Unpacking libc-dev-bin (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Preparing to unpack .../linux-libc-dev_4.15.0-176.185_amd64.deb ...\n",
      "Unpacking linux-libc-dev:amd64 (4.15.0-176.185) over (4.15.0-144.148) ...\n",
      "Preparing to unpack .../libc6_2.27-3ubuntu1.5_amd64.deb ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Unpacking libc6:amd64 (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Setting up libc6:amd64 (2.27-3ubuntu1.5) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../base-files_10.1ubuntu2.11_amd64.deb ...\n",
      "Unpacking base-files (10.1ubuntu2.11) over (10.1ubuntu2.10) ...\n",
      "Setting up base-files (10.1ubuntu2.11) ...\n",
      "Installing new version of config file /etc/issue ...\n",
      "Installing new version of config file /etc/issue.net ...\n",
      "Installing new version of config file /etc/lsb-release ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../bash_4.4.18-2ubuntu1.3_amd64.deb ...\n",
      "Unpacking bash (4.4.18-2ubuntu1.3) over (4.4.18-2ubuntu1.2) ...\n",
      "Setting up bash (4.4.18-2ubuntu1.3) ...\n",
      "update-alternatives: using /usr/share/man/man7/bash-builtins.7.gz to provide /usr/share/man/man7/builtins.7.gz (builtins.7.gz) in auto mode\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../gzip_1.6-5ubuntu1.2_amd64.deb ...\n",
      "Unpacking gzip (1.6-5ubuntu1.2) over (1.6-5ubuntu1) ...\n",
      "Setting up gzip (1.6-5ubuntu1.2) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../login_1%3a4.5-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking login (1:4.5-1ubuntu2.2) over (1:4.5-1ubuntu2) ...\n",
      "Setting up login (1:4.5-1ubuntu2.2) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../tar_1.29b-2ubuntu0.3_amd64.deb ...\n",
      "Unpacking tar (1.29b-2ubuntu0.3) over (1.29b-2ubuntu0.2) ...\n",
      "Setting up tar (1.29b-2ubuntu0.3) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../locales_2.27-3ubuntu1.5_all.deb ...\n",
      "Unpacking locales (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Preparing to unpack .../libc-bin_2.27-3ubuntu1.5_amd64.deb ...\n",
      "Unpacking libc-bin (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Setting up libc-bin (2.27-3ubuntu1.5) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../liblzma5_5.2.2-1.3ubuntu0.1_amd64.deb ...\n",
      "Unpacking liblzma5:amd64 (5.2.2-1.3ubuntu0.1) over (5.2.2-1.3) ...\n",
      "Setting up liblzma5:amd64 (5.2.2-1.3ubuntu0.1) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libsystemd0_237-3ubuntu10.53_amd64.deb ...\n",
      "Unpacking libsystemd0:amd64 (237-3ubuntu10.53) over (237-3ubuntu10.48) ...\n",
      "Setting up libsystemd0:amd64 (237-3ubuntu10.53) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libudev1_237-3ubuntu10.53_amd64.deb ...\n",
      "Unpacking libudev1:amd64 (237-3ubuntu10.53) over (237-3ubuntu10.48) ...\n",
      "Setting up libudev1:amd64 (237-3ubuntu10.53) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../zlib1g-dev_1%3a1.2.11.dfsg-0ubuntu2.1_amd64.deb ...\n",
      "Unpacking zlib1g-dev:amd64 (1:1.2.11.dfsg-0ubuntu2.1) over (1:1.2.11.dfsg-0ubuntu2) ...\n",
      "Preparing to unpack .../zlib1g_1%3a1.2.11.dfsg-0ubuntu2.1_amd64.deb ...\n",
      "Unpacking zlib1g:amd64 (1:1.2.11.dfsg-0ubuntu2.1) over (1:1.2.11.dfsg-0ubuntu2) ...\n",
      "Setting up zlib1g:amd64 (1:1.2.11.dfsg-0ubuntu2.1) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libapt-pkg5.0_1.6.14_amd64.deb ...\n",
      "Unpacking libapt-pkg5.0:amd64 (1.6.14) over (1.6.13) ...\n",
      "Setting up libapt-pkg5.0:amd64 (1.6.14) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libapt-inst2.0_1.6.14_amd64.deb ...\n",
      "Unpacking libapt-inst2.0:amd64 (1.6.14) over (1.6.13) ...\n",
      "Preparing to unpack .../archives/apt_1.6.14_amd64.deb ...\n",
      "Unpacking apt (1.6.14) over (1.6.13) ...\n",
      "Setting up apt (1.6.14) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../apt-utils_1.6.14_amd64.deb ...\n",
      "Unpacking apt-utils (1.6.14) over (1.6.13) ...\n",
      "Preparing to unpack .../libgnutls30_3.5.18-1ubuntu1.5_amd64.deb ...\n",
      "Unpacking libgnutls30:amd64 (3.5.18-1ubuntu1.5) over (3.5.18-1ubuntu1.4) ...\n",
      "Setting up libgnutls30:amd64 (3.5.18-1ubuntu1.5) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../libseccomp2_2.5.1-1ubuntu1~18.04.2_amd64.deb ...\n",
      "Unpacking libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.2) over (2.5.1-1ubuntu1~18.04.1) ...\n",
      "Setting up libseccomp2:amd64 (2.5.1-1ubuntu1~18.04.2) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libexpat1-dev_2.2.5-3ubuntu0.7_amd64.deb ...\n",
      "Unpacking libexpat1-dev:amd64 (2.2.5-3ubuntu0.7) over (2.2.5-3ubuntu0.2) ...\n",
      "Preparing to unpack .../01-libexpat1_2.2.5-3ubuntu0.7_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.2.5-3ubuntu0.7) over (2.2.5-3ubuntu0.2) ...\n",
      "Preparing to unpack .../02-python3.6-dev_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking python3.6-dev (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../03-libpython3.6-dev_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython3.6-dev:amd64 (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../04-libpython3.6_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython3.6:amd64 (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../05-libssl-dev_1.1.1-1ubuntu2.1~18.04.15_amd64.deb ...\n",
      "Unpacking libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.15) over (1.1.1-1ubuntu2.1~18.04.9) ...\n",
      "Preparing to unpack .../06-libssl1.1_1.1.1-1ubuntu2.1~18.04.15_amd64.deb ...\n",
      "Unpacking libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.15) over (1.1.1-1ubuntu2.1~18.04.9) ...\n",
      "Preparing to unpack .../07-python3.6_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking python3.6 (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../08-libpython3.6-stdlib_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython3.6-stdlib:amd64 (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../09-python3.6-minimal_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking python3.6-minimal (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../10-libpython3.6-minimal_3.6.9-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython3.6-minimal:amd64 (3.6.9-1~18.04ubuntu1.7) over (3.6.9-1~18.04ubuntu1.4) ...\n",
      "Preparing to unpack .../11-python2.7_2.7.17-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.17-1~18.04ubuntu1.7) over (2.7.17-1~18.04ubuntu1.6) ...\n",
      "Preparing to unpack .../12-libpython2.7-stdlib_2.7.17-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.17-1~18.04ubuntu1.7) over (2.7.17-1~18.04ubuntu1.6) ...\n",
      "Preparing to unpack .../13-python2.7-minimal_2.7.17-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.17-1~18.04ubuntu1.7) over (2.7.17-1~18.04ubuntu1.6) ...\n",
      "Preparing to unpack .../14-libpython2.7-minimal_2.7.17-1~18.04ubuntu1.7_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.17-1~18.04ubuntu1.7) over (2.7.17-1~18.04ubuntu1.6) ...\n",
      "Preparing to unpack .../15-libgcrypt20_1.8.1-4ubuntu1.3_amd64.deb ...\n",
      "Unpacking libgcrypt20:amd64 (1.8.1-4ubuntu1.3) over (1.8.1-4ubuntu1.2) ...\n",
      "Setting up libgcrypt20:amd64 (1.8.1-4ubuntu1.3) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../passwd_1%3a4.5-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking passwd (1:4.5-1ubuntu2.2) over (1:4.5-1ubuntu2) ...\n",
      "Setting up passwd (1:4.5-1ubuntu2.2) ...\n",
      "(Reading database ... 58582 files and directories currently installed.)\n",
      "Preparing to unpack .../00-openssl_1.1.1-1ubuntu2.1~18.04.15_amd64.deb ...\n",
      "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.15) over (1.1.1-1ubuntu2.1~18.04.9) ...\n",
      "Preparing to unpack .../01-ca-certificates_20210119~18.04.2_all.deb ...\n",
      "Unpacking ca-certificates (20210119~18.04.2) over (20210119~18.04.1) ...\n",
      "Preparing to unpack .../02-distro-info-data_0.37ubuntu0.13_all.deb ...\n",
      "Unpacking distro-info-data (0.37ubuntu0.13) over (0.37ubuntu0.10) ...\n",
      "Preparing to unpack .../03-libglib2.0-0_2.56.4-0ubuntu0.18.04.9_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.9) over (2.56.4-0ubuntu0.18.04.8) ...\n",
      "Preparing to unpack .../04-libicu60_60.2-3ubuntu3.2_amd64.deb ...\n",
      "Unpacking libicu60:amd64 (60.2-3ubuntu3.2) over (60.2-3ubuntu3.1) ...\n",
      "Preparing to unpack .../05-libxml2_2.9.4+dfsg1-6.1ubuntu1.5_amd64.deb ...\n",
      "Unpacking libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.5) over (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
      "Preparing to unpack .../06-tzdata_2022a-0ubuntu0.18.04_all.deb ...\n",
      "Unpacking tzdata (2022a-0ubuntu0.18.04) over (2021a-0ubuntu0.18.04) ...\n",
      "Preparing to unpack .../07-libruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
      "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.11) over (2.5.1-1ubuntu1.9) ...\n",
      "Preparing to unpack .../08-vim-nox_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
      "Unpacking vim-nox (2:8.0.1453-1ubuntu1.8) over (2:8.0.1453-1ubuntu1.4) ...\n",
      "Preparing to unpack .../09-vim-tiny_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
      "Unpacking vim-tiny (2:8.0.1453-1ubuntu1.8) over (2:8.0.1453-1ubuntu1.4) ...\n",
      "Preparing to unpack .../10-vim-runtime_2%3a8.0.1453-1ubuntu1.8_all.deb ...\n",
      "Unpacking vim-runtime (2:8.0.1453-1ubuntu1.8) over (2:8.0.1453-1ubuntu1.4) ...\n",
      "Preparing to unpack .../11-xxd_2%3a8.0.1453-1ubuntu1.8_amd64.deb ...\n",
      "Unpacking xxd (2:8.0.1453-1ubuntu1.8) over (2:8.0.1453-1ubuntu1.4) ...\n",
      "Preparing to unpack .../12-vim-common_2%3a8.0.1453-1ubuntu1.8_all.deb ...\n",
      "Unpacking vim-common (2:8.0.1453-1ubuntu1.8) over (2:8.0.1453-1ubuntu1.4) ...\n",
      "Preparing to unpack .../13-xz-utils_5.2.2-1.3ubuntu0.1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.2-1.3ubuntu0.1) over (5.2.2-1.3) ...\n",
      "Preparing to unpack .../14-libirs160_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../15-bind9-host_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking bind9-host (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../16-dnsutils_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking dnsutils (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../17-libbind9-160_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../18-libisccfg160_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../19-libisccc160_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../20-libdns1100_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../21-libisc169_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../22-liblwres160_1%3a9.11.3+dfsg-1ubuntu1.17_amd64.deb ...\n",
      "Unpacking liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) over (1:9.11.3+dfsg-1ubuntu1.15) ...\n",
      "Preparing to unpack .../23-libkeyutils1_1.5.9-9.2ubuntu2.1_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.5.9-9.2ubuntu2.1) over (1.5.9-9.2ubuntu2) ...\n",
      "Preparing to unpack .../24-libssl1.0.0_1.0.2n-1ubuntu5.8_amd64.deb ...\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2n-1ubuntu5.8) over (1.0.2n-1ubuntu5.6) ...\n",
      "Preparing to unpack .../25-multiarch-support_2.27-3ubuntu1.5_amd64.deb ...\n",
      "Unpacking multiarch-support (2.27-3ubuntu1.5) over (2.27-3ubuntu1.4) ...\n",
      "Preparing to unpack .../26-openssh-sftp-server_1%3a7.6p1-4ubuntu0.6_amd64.deb ...\n",
      "Unpacking openssh-sftp-server (1:7.6p1-4ubuntu0.6) over (1:7.6p1-4ubuntu0.3) ...\n",
      "Preparing to unpack .../27-openssh-server_1%3a7.6p1-4ubuntu0.6_amd64.deb ...\n",
      "Unpacking openssh-server (1:7.6p1-4ubuntu0.6) over (1:7.6p1-4ubuntu0.3) ...\n",
      "Preparing to unpack .../28-git-man_1%3a2.17.1-1ubuntu0.10_all.deb ...\n",
      "Unpacking git-man (1:2.17.1-1ubuntu0.10) over (1:2.17.1-1ubuntu0.8) ...\n",
      "Preparing to unpack .../29-libcurl3-gnutls_7.58.0-2ubuntu3.16_amd64.deb ...\n",
      "Unpacking libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.16) over (7.58.0-2ubuntu3.13) ...\n",
      "Preparing to unpack .../30-git_1%3a2.17.1-1ubuntu0.10_amd64.deb ...\n",
      "Unpacking git (1:2.17.1-1ubuntu0.10) over (1:2.17.1-1ubuntu0.8) ...\n",
      "Preparing to unpack .../31-openssh-client_1%3a7.6p1-4ubuntu0.6_amd64.deb ...\n",
      "Unpacking openssh-client (1:7.6p1-4ubuntu0.6) over (1:7.6p1-4ubuntu0.3) ...\n",
      "Preparing to unpack .../32-python-apt-common_1.6.5ubuntu0.7_all.deb ...\n",
      "Unpacking python-apt-common (1.6.5ubuntu0.7) over (1.6.5ubuntu0.6) ...\n",
      "Preparing to unpack .../33-python3-apt_1.6.5ubuntu0.7_amd64.deb ...\n",
      "Unpacking python3-apt (1.6.5ubuntu0.7) over (1.6.5ubuntu0.6) ...\n",
      "Preparing to unpack .../34-rsync_3.1.2-2.1ubuntu1.4_amd64.deb ...\n",
      "Unpacking rsync (3.1.2-2.1ubuntu1.4) over (3.1.2-2.1ubuntu1.1) ...\n",
      "Preparing to unpack .../35-apt-transport-https_1.6.14_all.deb ...\n",
      "Unpacking apt-transport-https (1.6.14) over (1.6.13) ...\n",
      "Preparing to unpack .../36-binutils-x86-64-linux-gnu_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.5) ...\n",
      "Preparing to unpack .../37-binutils-common_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.5) ...\n",
      "Preparing to unpack .../38-binutils_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
      "Unpacking binutils (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.5) ...\n",
      "Preparing to unpack .../39-libbinutils_2.30-21ubuntu1~18.04.7_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.30-21ubuntu1~18.04.7) over (2.30-21ubuntu1~18.04.5) ...\n",
      "Preparing to unpack .../40-curl_7.58.0-2ubuntu3.16_amd64.deb ...\n",
      "Unpacking curl (7.58.0-2ubuntu3.16) over (7.58.0-2ubuntu3.13) ...\n",
      "Preparing to unpack .../41-libcurl4_7.58.0-2ubuntu3.16_amd64.deb ...\n",
      "Unpacking libcurl4:amd64 (7.58.0-2ubuntu3.16) over (7.58.0-2ubuntu3.13) ...\n",
      "Preparing to unpack .../42-google-cloud-sdk_382.0.0-0_all.deb ...\n",
      "Unpacking google-cloud-sdk (382.0.0-0) over (345.0.0-0) ...\n",
      "Preparing to unpack .../43-libasound2_1.1.3-5ubuntu0.6_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.3-5ubuntu0.6) over (1.1.3-5ubuntu0.5) ...\n",
      "Preparing to unpack .../44-libasound2-data_1.1.3-5ubuntu0.6_all.deb ...\n",
      "Unpacking libasound2-data (1.1.3-5ubuntu0.6) over (1.1.3-5ubuntu0.5) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to unpack .../45-libgd3_2.2.5-4ubuntu0.5_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.5) over (2.2.5-4ubuntu0.4) ...\n",
      "Preparing to unpack .../46-libmysqlclient-dev_5.7.37-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libmysqlclient-dev (5.7.37-0ubuntu0.18.04.1) over (5.7.34-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../47-libmysqlclient20_5.7.37-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libmysqlclient20:amd64 (5.7.37-0ubuntu0.18.04.1) over (5.7.34-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../48-libpq5_10.19-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking libpq5:amd64 (10.19-0ubuntu0.18.04.1) over (10.17-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../49-libsasl2-modules-db_2.1.27~101-g0780600+dfsg-3ubuntu2.4_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) over (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\n",
      "Preparing to unpack .../50-libsasl2-2_2.1.27~101-g0780600+dfsg-3ubuntu2.4_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) over (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\n",
      "Preparing to unpack .../51-mysql-client-core-5.7_5.7.37-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking mysql-client-core-5.7 (5.7.37-0ubuntu0.18.04.1) over (5.7.34-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../52-mysql-client-5.7_5.7.37-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking mysql-client-5.7 (5.7.37-0ubuntu0.18.04.1) over (5.7.34-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../53-mysql-client_5.7.37-0ubuntu0.18.04.1_all.deb ...\n",
      "Unpacking mysql-client (5.7.37-0ubuntu0.18.04.1) over (5.7.34-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../54-postgresql-client-10_10.19-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking postgresql-client-10 (10.19-0ubuntu0.18.04.1) over (10.17-0ubuntu0.18.04.1) ...\n",
      "Preparing to unpack .../55-software-properties-common_0.96.24.32.18_all.deb ...\n",
      "Unpacking software-properties-common (0.96.24.32.18) over (0.96.24.32.14) ...\n",
      "Preparing to unpack .../56-python3-software-properties_0.96.24.32.18_all.deb ...\n",
      "Unpacking python3-software-properties (0.96.24.32.18) over (0.96.24.32.14) ...\n",
      "Preparing to unpack .../57-ruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
      "Unpacking ruby2.5 (2.5.1-1ubuntu1.11) over (2.5.1-1ubuntu1.9) ...\n",
      "Setting up python-apt-common (1.6.5ubuntu0.7) ...\n",
      "Setting up libapt-inst2.0:amd64 (1.6.14) ...\n",
      "Setting up git-man (1:2.17.1-1ubuntu0.10) ...\n",
      "Setting up libexpat1:amd64 (2.2.5-3ubuntu0.7) ...\n",
      "Setting up libicu60:amd64 (60.2-3ubuntu3.2) ...\n",
      "Setting up apt-transport-https (1.6.14) ...\n",
      "Setting up python3-apt (1.6.5ubuntu0.7) ...\n",
      "Setting up libssl1.0.0:amd64 (1.0.2n-1ubuntu5.8) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up xxd (2:8.0.1453-1ubuntu1.8) ...\n",
      "Setting up apt-utils (1.6.14) ...\n",
      "Setting up libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.16) ...\n",
      "Setting up multiarch-support (2.27-3ubuntu1.5) ...\n",
      "Setting up tzdata (2022a-0ubuntu0.18.04) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "\n",
      "Current default time zone: 'Etc/UTC'\n",
      "Local time is now:      Sun Apr 24 17:23:43 UTC 2022.\n",
      "Universal Time is now:  Sun Apr 24 17:23:43 UTC 2022.\n",
      "Run 'dpkg-reconfigure tzdata' if you wish to change it.\n",
      "\n",
      "Setting up libglib2.0-0:amd64 (2.56.4-0ubuntu0.18.04.9) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up libasound2-data (1.1.3-5ubuntu0.6) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) ...\n",
      "Setting up linux-libc-dev:amd64 (4.15.0-176.185) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.4) ...\n",
      "Setting up libgd3:amd64 (2.2.5-4ubuntu0.5) ...\n",
      "Setting up distro-info-data (0.37ubuntu0.13) ...\n",
      "Setting up libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.5) ...\n",
      "Setting up libasound2:amd64 (1.1.3-5ubuntu0.6) ...\n",
      "Setting up rsync (3.1.2-2.1ubuntu1.4) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of restart.\n",
      "Setting up binutils-common:amd64 (2.30-21ubuntu1~18.04.7) ...\n",
      "Setting up libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.15) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up xz-utils (5.2.2-1.3ubuntu0.1) ...\n",
      "Setting up openssl (1.1.1-1ubuntu2.1~18.04.15) ...\n",
      "Setting up vim-common (2:8.0.1453-1ubuntu1.8) ...\n",
      "Setting up python3-software-properties (0.96.24.32.18) ...\n",
      "Setting up vim-runtime (2:8.0.1453-1ubuntu1.8) ...\n",
      "Setting up libmysqlclient20:amd64 (5.7.37-0ubuntu0.18.04.1) ...\n",
      "Setting up libc-dev-bin (2.27-3ubuntu1.5) ...\n",
      "Setting up libkeyutils1:amd64 (1.5.9-9.2ubuntu2.1) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.17-1~18.04ubuntu1.7) ...\n",
      "Setting up mysql-client-core-5.7 (5.7.37-0ubuntu0.18.04.1) ...\n",
      "Setting up google-cloud-sdk (382.0.0-0) ...\n",
      "Setting up ca-certificates (20210119~18.04.2) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 1 removed; done.\n",
      "Setting up openssh-client (1:7.6p1-4ubuntu0.6) ...\n",
      "Setting up libc6-dev:amd64 (2.27-3ubuntu1.5) ...\n",
      "Setting up locales (2.27-3ubuntu1.5) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Generating locales (this might take a while)...\n",
      "  en_AG.UTF-8... done\n",
      "  en_AU.UTF-8... done\n",
      "  en_BW.UTF-8... done\n",
      "  en_CA.UTF-8... done\n",
      "  en_DK.UTF-8... done\n",
      "  en_GB.UTF-8... done\n",
      "  en_HK.UTF-8... done\n",
      "  en_IE.UTF-8... done\n",
      "  en_IL.UTF-8... done\n",
      "  en_IN.UTF-8... done\n",
      "  en_NG.UTF-8... done\n",
      "  en_NZ.UTF-8... done\n",
      "  en_PH.UTF-8... done\n",
      "  en_SG.UTF-8... done\n",
      "  en_US.ISO-8859-1... done\n",
      "  en_US.UTF-8... done\n",
      "  en_ZA.UTF-8... done\n",
      "  en_ZM.UTF-8... done\n",
      "  en_ZW.UTF-8... done\n",
      "Generation complete.\n",
      "Setting up liblwres160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up git (1:2.17.1-1ubuntu0.10) ...\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.17-1~18.04ubuntu1.7) ...\n",
      "Setting up python2.7-minimal (2.7.17-1~18.04ubuntu1.7) ...\n",
      "Setting up zlib1g-dev:amd64 (1:1.2.11.dfsg-0ubuntu2.1) ...\n",
      "Setting up software-properties-common (0.96.24.32.18) ...\n",
      "Setting up vim-tiny (2:8.0.1453-1ubuntu1.8) ...\n",
      "Setting up libisc169:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.11) ...\n",
      "Setting up libisccc160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up libbinutils:amd64 (2.30-21ubuntu1~18.04.7) ...\n",
      "Setting up libssl-dev:amd64 (1.1.1-1ubuntu2.1~18.04.15) ...\n",
      "Setting up libcurl4:amd64 (7.58.0-2ubuntu3.16) ...\n",
      "Setting up python2.7 (2.7.17-1~18.04ubuntu1.7) ...\n",
      "Setting up libpython3.6-minimal:amd64 (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up libpq5:amd64 (10.19-0ubuntu0.18.04.1) ...\n",
      "Setting up openssh-sftp-server (1:7.6p1-4ubuntu0.6) ...\n",
      "Setting up libexpat1-dev:amd64 (2.2.5-3ubuntu0.7) ...\n",
      "Setting up mysql-client-5.7 (5.7.37-0ubuntu0.18.04.1) ...\n",
      "Setting up libdns1100:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up postgresql-client-10 (10.19-0ubuntu0.18.04.1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.30-21ubuntu1~18.04.7) ...\n",
      "Setting up libpython3.6-stdlib:amd64 (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up ruby2.5 (2.5.1-1ubuntu1.11) ...\n",
      "Setting up libmysqlclient-dev (5.7.37-0ubuntu0.18.04.1) ...\n",
      "Setting up curl (7.58.0-2ubuntu3.16) ...\n",
      "Setting up python3.6-minimal (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up mysql-client (5.7.37-0ubuntu0.18.04.1) ...\n",
      "Setting up libisccfg160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up openssh-server (1:7.6p1-4ubuntu0.6) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of restart.\n",
      "Setting up binutils (2.30-21ubuntu1~18.04.7) ...\n",
      "Setting up libpython3.6:amd64 (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up python3.6 (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up libirs160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up vim-nox (2:8.0.1453-1ubuntu1.8) ...\n",
      "Setting up libbind9-160:amd64 (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up libpython3.6-dev:amd64 (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up python3.6-dev (3.6.9-1~18.04ubuntu1.7) ...\n",
      "Setting up bind9-host (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Setting up dnsutils (1:9.11.3+dfsg-1ubuntu1.17) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for install-info (6.5.0.dfsg.1-2) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
      "Processing triggers for ca-certificates (20210119~18.04.2) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  python3-crcmod\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java java-common libavahi-client3 libavahi-common-data\n",
      "  libavahi-common3 libcups2 liblcms2-2 libnspr4 libnss3 libpcsclite1 libxi6\n",
      "  libxtst6 openjdk-8-jre-headless\n",
      "Suggested packages:\n",
      "  default-jre cups-common liblcms2-utils pcscd openjdk-8-demo openjdk-8-source\n",
      "  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
      "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java java-common libavahi-client3 libavahi-common-data\n",
      "  libavahi-common3 libcups2 liblcms2-2 libnspr4 libnss3 libpcsclite1 libxi6\n",
      "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
      "0 upgraded, 14 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 38.4 MB of archives.\n",
      "After this operation, 149 MB of additional disk space will be used.\n",
      "Get:1 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 java-common all 0.68ubuntu1~18.04.1 [14.5 kB]\n",
      "Get:2 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common-data amd64 0.7-3.1ubuntu1.3 [22.2 kB]\n",
      "Get:3 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-common3 amd64 0.7-3.1ubuntu1.3 [21.6 kB]\n",
      "Get:4 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libavahi-client3 amd64 0.7-3.1ubuntu1.3 [25.2 kB]\n",
      "Get:5 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcups2 amd64 2.2.7-1ubuntu2.8 [211 kB]\n",
      "Get:6 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblcms2-2 amd64 2.9-1ubuntu0.1 [139 kB]\n",
      "Get:7 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 libnspr4 amd64 2:4.18-1ubuntu1 [112 kB]\n",
      "Get:8 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnss3 amd64 2:3.35-2ubuntu2.13 [1,220 kB]\n",
      "Get:9 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 libpcsclite1 amd64 1.8.23-1 [21.3 kB]\n",
      "Get:10 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
      "Get:11 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
      "Get:12 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u312-b07-0ubuntu1~18.04 [28.2 MB]\n",
      "Get:13 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/main amd64 ca-certificates-java all 20180516ubuntu1~18.04.1 [12.2 kB]\n",
      "Get:14 http://eu-west-1.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u312-b07-0ubuntu1~18.04 [8,298 kB]\n",
      "Fetched 38.4 MB in 1s (57.0 MB/s)              \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Selecting previously unselected package java-common.\n",
      "(Reading database ... 68102 files and directories currently installed.)\n",
      "Preparing to unpack .../00-java-common_0.68ubuntu1~18.04.1_all.deb ...\n",
      "Unpacking java-common (0.68ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package libavahi-common-data:amd64.\n",
      "Preparing to unpack .../01-libavahi-common-data_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-common-data:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libavahi-common3:amd64.\n",
      "Preparing to unpack .../02-libavahi-common3_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-common3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libavahi-client3:amd64.\n",
      "Preparing to unpack .../03-libavahi-client3_0.7-3.1ubuntu1.3_amd64.deb ...\n",
      "Unpacking libavahi-client3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Selecting previously unselected package libcups2:amd64.\n",
      "Preparing to unpack .../04-libcups2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
      "Unpacking libcups2:amd64 (2.2.7-1ubuntu2.8) ...\n",
      "Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../05-liblcms2-2_2.9-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../06-libnspr4_2%3a4.18-1ubuntu1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../07-libnss3_2%3a3.35-2ubuntu2.13_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.35-2ubuntu2.13) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../08-libpcsclite1_1.8.23-1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.23-1) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../09-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../10-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../11-openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../12-ca-certificates-java_20180516ubuntu1~18.04.1_all.deb ...\n",
      "Unpacking ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../13-openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up liblcms2-2:amd64 (2.9-1ubuntu0.1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.23-1) ...\n",
      "Setting up java-common (0.68ubuntu1~18.04.1) ...\n",
      "Setting up libnspr4:amd64 (2:4.18-1ubuntu1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Setting up libavahi-common-data:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libnss3:amd64 (2:3.35-2ubuntu2.13) ...\n",
      "Setting up libavahi-common3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libavahi-client3:amd64 (0.7-3.1ubuntu1.3) ...\n",
      "Setting up libcups2:amd64 (2.2.7-1ubuntu2.8) ...\n",
      "Setting up ca-certificates-java (20180516ubuntu1~18.04.1) ...\n",
      "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
      "Adding debian:e-Szigno_Root_CA_2017.pem\n",
      "Adding debian:certSIGN_Root_CA_G2.pem\n",
      "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "done.\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for ca-certificates (20210119~18.04.2) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "/project /project/MSIN0166_Data_Engineering_individual\n",
      "spark-3.2.1-bin-hadoop3.2/\n",
      "spark-3.2.1-bin-hadoop3.2/LICENSE\n",
      "spark-3.2.1-bin-hadoop3.2/NOTICE\n",
      "spark-3.2.1-bin-hadoop3.2/R/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/INDEX\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/html/R.css\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n",
      "spark-3.2.1-bin-hadoop3.2/R/lib/sparkr.zip\n",
      "spark-3.2.1-bin-hadoop3.2/README.md\n",
      "spark-3.2.1-bin-hadoop3.2/RELEASE\n",
      "spark-3.2.1-bin-hadoop3.2/bin/\n",
      "spark-3.2.1-bin-hadoop3.2/bin/beeline\n",
      "spark-3.2.1-bin-hadoop3.2/bin/beeline.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/docker-image-tool.sh\n",
      "spark-3.2.1-bin-hadoop3.2/bin/find-spark-home\n",
      "spark-3.2.1-bin-hadoop3.2/bin/find-spark-home.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/load-spark-env.sh\n",
      "spark-3.2.1-bin-hadoop3.2/bin/pyspark\n",
      "spark-3.2.1-bin-hadoop3.2/bin/pyspark.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/pyspark2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/run-example\n",
      "spark-3.2.1-bin-hadoop3.2/bin/run-example.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-class\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-class.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-class2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-shell\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-shell.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-shell2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-sql\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-sql.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-sql2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-submit\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-submit.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/spark-submit2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/sparkR\n",
      "spark-3.2.1-bin-hadoop3.2/bin/sparkR.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/bin/sparkR2.cmd\n",
      "spark-3.2.1-bin-hadoop3.2/conf/\n",
      "spark-3.2.1-bin-hadoop3.2/conf/fairscheduler.xml.template\n",
      "spark-3.2.1-bin-hadoop3.2/conf/log4j.properties.template\n",
      "spark-3.2.1-bin-hadoop3.2/conf/metrics.properties.template\n",
      "spark-3.2.1-bin-hadoop3.2/conf/spark-defaults.conf.template\n",
      "spark-3.2.1-bin-hadoop3.2/conf/spark-env.sh.template\n",
      "spark-3.2.1-bin-hadoop3.2/conf/workers.template\n",
      "spark-3.2.1-bin-hadoop3.2/data/\n",
      "spark-3.2.1-bin-hadoop3.2/data/graphx/\n",
      "spark-3.2.1-bin-hadoop3.2/data/graphx/followers.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/graphx/users.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/als/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/als/test.data\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/gmm_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/license.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/license.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/kmeans_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/pagerank_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/pic_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n",
      "spark-3.2.1-bin-hadoop3.2/data/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/data/streaming/AFINN-111.txt\n",
      "spark-3.2.1-bin-hadoop3.2/examples/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/jars/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/als.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/kmeans.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pagerank.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/pi.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sort.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/python/wordcount.py\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/dataframe.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/als.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/employees.json\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.csv\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.json\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/people.txt\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/user.avsc\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.avro\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.orc\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/resources/users.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/\n",
      "spark-3.2.1-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n",
      "spark-3.2.1-bin-hadoop3.2/jars/\n",
      "spark-3.2.1-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/JTransforms-3.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/RoaringBitmap-0.9.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/ST4-4.0.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/activation-1.1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/aircompressor-0.21.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/algebra_2.12-2.0.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/annotations-17.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/antlr4-runtime-4.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arpack-2.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arrow-format-2.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-core-2.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arrow-memory-netty-2.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/arrow-vector-2.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/automaton-1.11-8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/avro-1.10.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/avro-ipc-1.10.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/avro-mapred-1.10.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/blas-2.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/breeze-macros_2.12-1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/breeze_2.12-1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/cats-kernel_2.12-2.1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/chill-java-0.10.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/chill_2.12-0.10.0.jar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/jars/commons-cli-1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-codec-1.15.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-compress-1.21.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-crypto-1.1.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-io-2.8.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-lang-2.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-lang3-3.12.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-net-3.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/commons-text-1.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/core-1.1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/derby-10.14.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/generex-1.0.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/gson-2.2.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/guava-14.0.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-api-3.3.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hadoop-client-runtime-3.3.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hadoop-shaded-guava-1.1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.3.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-beeline-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-cli-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-common-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-exec-2.3.9-core.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-jdbc-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-llap-common-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-metastore-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-serde-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-service-rpc-3.1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-0.23-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-common-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-storage-api-2.7.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.9.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/httpclient-4.5.13.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/httpcore-4.4.14.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/ivy-2.5.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-annotations-2.12.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-core-2.12.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-databind-2.12.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.12.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.11.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.12.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.servlet-api-4.0.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/janino-3.0.16.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/javolution-5.5.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-client-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-common-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-container-servlet-core-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-hk2-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jersey-server-2.34.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jline-2.14.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/joda-time-2.10.10.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jpam-1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/json-1.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/json4s-core_2.12-3.7.0-M11.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jta-1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-client-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-admissionregistration-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apiextensions-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-apps-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-autoscaling-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-batch-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-certificates-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-common-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-coordination-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-core-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-discovery-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-events-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-extensions-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-flowcontrol-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-metrics-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-networking-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-node-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-policy-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-rbac-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-scheduling-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/kubernetes-model-storageclass-5.4.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/lapack-2.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/log4j-1.2.17.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/logging-interceptor-3.12.12.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/metrics-core-4.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/metrics-graphite-4.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/metrics-jmx-4.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/metrics-json-4.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/metrics-jvm-4.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/minlog-1.3.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/netty-all-4.1.68.Final.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/objenesis-2.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/okhttp-3.12.12.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/okio-1.14.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/opencsv-2.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/orc-core-1.6.12.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/orc-mapreduce-1.6.12.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/orc-shims-1.6.12.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/oro-2.0.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/jars/paranamer-2.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-column-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-common-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-encoding-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-format-structures-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-hadoop-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/parquet-jackson-1.12.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/py4j-0.10.9.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/pyrolite-4.30.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/rocksdbjni-6.20.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-compiler-2.12.15.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-library-2.12.15.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-reflect-2.12.15.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/shims-0.9.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/snakeyaml-1.27.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/snappy-java-1.1.8.4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-catalyst_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-core_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-graphx_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-hive_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-kvstore_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-launcher_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-mesos_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-mllib_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-network-common_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-repl_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-sketch_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-sql_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-streaming_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1-tests.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-tags_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spark-yarn_2.12-3.2.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spire-util_2.12-0.17.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/spire_2.12-0.17.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/stream-2.9.6.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/tink-1.6.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/transaction-api-1.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/univocity-parsers-2.9.1.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/velocity-1.5.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/xbean-asm9-shaded-4.20.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/xz-1.8.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/zookeeper-3.6.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/zookeeper-jute-3.6.2.jar\n",
      "spark-3.2.1-bin-hadoop3.2/jars/zstd-jni-1.5.0-4.jar\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/autoscale.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n",
      "spark-3.2.1-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-blas.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-janino.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javassist.html\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jline.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-join.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-respond.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scala.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-spire.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n",
      "spark-3.2.1-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/\n",
      "spark-3.2.1-bin-hadoop3.2/python/.coveragerc\n",
      "spark-3.2.1-bin-hadoop3.2/python/.gitignore\n",
      "spark-3.2.1-bin-hadoop3.2/python/MANIFEST.in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/python/README.md\n",
      "spark-3.2.1-bin-hadoop3.2/python/dist/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/Makefile\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/make.bat\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/make2.bat\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/copybutton.js\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_static/css/pyspark.css\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/conf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/contributing.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/debugging.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/setting_ide.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/development/testing.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/install.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_df.ipynb\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/getting_started/quickstart_ps.ipynb\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ml.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.mllib.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/frame.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/io.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/ml.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/series.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.pandas/window.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.resource.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.sql.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.ss.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/reference/pyspark.streaming.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/arrow_pandas.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/python_packaging.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/docs/source/user_guide/sql/index.rst\n",
      "spark-3.2.1-bin-hadoop3.2/python/lib/\n",
      "spark-3.2.1-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/lib/py4j-0.10.9.3-src.zip\n",
      "spark-3.2.1-bin-hadoop3.2/python/lib/pyspark.zip\n",
      "spark-3.2.1-bin-hadoop3.2/python/mypy.ini\n",
      "spark-3.2.1-bin-hadoop3.2/python/pylintrc\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/__pycache__/install.cpython-38.pyc\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/_globals.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/_typing.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/accumulators.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/broadcast.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/cloudpickle/compat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/conf.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/context.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/daemon.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/files.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/files.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/find_spark_home.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/install.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/java_gateway.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/join.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/_typing.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/base.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/classification.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/clustering.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/common.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/evaluation.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/feature.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/fpm.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/functions.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/image.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/param/shared.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/pipeline.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/recommendation.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/regression.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/stat.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tree.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/tuning.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/util.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/ml/wrapper.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/_typing.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/classification.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/clustering.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/common.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/evaluation.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/feature.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/fpm.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/random.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/recommendation.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/regression.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/stat/test.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/tree.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/mllib/util.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/_typing.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/accessors.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/categorical.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/config.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/date_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/null_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/num_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/string_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/datetimes.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/exceptions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/extensions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/frame.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/generic.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/groupby.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/category.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/datetimes.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/multi.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexes/numeric.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/indexing.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/internal.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/common.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/frame.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/groupby.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/indexes.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/series.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/missing/window.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/ml.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/mlflow.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/namespace.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/numpy_compat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/core.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/matplotlib.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/plot/plotly.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/series.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/accessors.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/spark/utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/sql_processor.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/strings.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_base.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_category.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_categorical.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_config.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_csv.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_default_index.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_expanding.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_extension.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_frame_spark.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_groupby.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexing.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_indexops_spark.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_internal.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_namespace.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_numpy_compat.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_repr.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_reshape.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_rolling.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_conversion.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_datetime.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_series_string.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_spark_functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_sql.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_stats.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_typedef.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/tests/test_window.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/string_typehints.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/typedef/typehints.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/usage_logging/usage_logger.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/pandas/window.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/profiler.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/py.typed\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/python/pyspark/shell.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/rdd.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/rddsampler.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/information.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/profile.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/requests.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resource/tests/test_resources.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/resultiterable.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/serializers.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/shell.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/shuffle.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/_typing.pyi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/avro/functions.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/catalog.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/column.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/conf.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/context.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/dataframe.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/functions.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/group.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/functions.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/readwriter.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/session.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/streaming.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/types.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/udf.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/sql/window.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/statcounter.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/status.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/status.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/storagelevel.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/context.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/dstream.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/kinesis.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/listener.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/streaming/util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/taskcontext.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/pandasutils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/testing/utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/__init__.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_context.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_install_spark.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_join.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_util.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/traceback_utils.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/util.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/util.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/version.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/version.pyi\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark/worker.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/PKG-INFO\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/SOURCES.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/dependency_links.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/requires.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/pyspark.egg-info/top_level.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/run-tests\n",
      "spark-3.2.1-bin-hadoop3.2/python/run-tests-with-coverage\n",
      "spark-3.2.1-bin-hadoop3.2/python/run-tests.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/setup.cfg\n",
      "spark-3.2.1-bin-hadoop3.2/python/setup.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_coverage/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/hello.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages.csv\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people.json\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people1.json\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array.json\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/sql/text-test.txt\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n",
      "spark-3.2.1-bin-hadoop3.2/python/test_support/userlibrary.py\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/decommission-slave.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/decommission-worker.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/slaves.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/spark-config.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/spark-daemon.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/spark-daemons.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-all.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-history-server.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-master.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-slave.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-slaves.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-thriftserver.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-worker.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/start-workers.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-all.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-history-server.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-master.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-slave.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-slaves.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-thriftserver.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-worker.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/stop-workers.sh\n",
      "spark-3.2.1-bin-hadoop3.2/sbin/workers.sh\n",
      "spark-3.2.1-bin-hadoop3.2/yarn/\n",
      "spark-3.2.1-bin-hadoop3.2/yarn/spark-3.2.1-yarn-shuffle.jar\n",
      "/project/MSIN0166_Data_Engineering_individual\n",
      "Collecting pyspark\n",
      "  Using cached pyspark-3.2.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.3\n",
      "  Using cached py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "# install the spark\n",
    "!bash install_spark.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66617360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the spark envrionment\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/project/spark-3.2.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eda8adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PySpark App\").config(\"spark.jars\", \"postgresql-42.3.2.jar\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\",\"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba38cc",
   "metadata": {},
   "source": [
    "# Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd83b9",
   "metadata": {},
   "source": [
    "Firstly, the team's basic information is gathered by using BeautifulSoup from https://www.basketball-reference.com/ . The information on winning and losing is in the same line with the team link and team full name for each team. The line of information is further processed to get the corresponding information and form it in a dictionary.\n",
    "\n",
    "Secondly, the playoff team information is gathered from https://www.basketball-reference.com/playoffs/NBA_2022.html . Where only the teams in the playoff are listed.\n",
    "\n",
    "Lastly, form the team's basic information into a data frame and merge the playoff data for each team into the data frame. The data frame will be converted into a spark data frame and the schema is printed to check the data type for each column. Finally, the spark data frame is output as a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8c8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using BeautifulSoup to get the web page information\n",
    "URL =\"https://www.basketball-reference.com/\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup_body = str(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccecc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the team related data\n",
    "list_info = re.findall(r'data-stat=\"payroll_text\">(.*)</td></tr>', soup_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746816cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<a href=\"/contracts/MIA.html\" title=\"Miami Heat Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">53</td><td class=\"right\" data-stat=\"losses\">29',\n",
       " '<a href=\"/contracts/BOS.html\" title=\"Boston Celtics Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">51</td><td class=\"right\" data-stat=\"losses\">31',\n",
       " '<a href=\"/contracts/MIL.html\" title=\"Milwaukee Bucks Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">51</td><td class=\"right\" data-stat=\"losses\">31',\n",
       " '<a href=\"/contracts/PHI.html\" title=\"Philadelphia 76ers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">51</td><td class=\"right\" data-stat=\"losses\">31',\n",
       " '<a href=\"/contracts/TOR.html\" title=\"Toronto Raptors Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">48</td><td class=\"right\" data-stat=\"losses\">34',\n",
       " '<a href=\"/contracts/CHI.html\" title=\"Chicago Bulls Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">46</td><td class=\"right\" data-stat=\"losses\">36',\n",
       " '<a href=\"/contracts/BRK.html\" title=\"Brooklyn Nets Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">44</td><td class=\"right\" data-stat=\"losses\">38',\n",
       " '<a href=\"/contracts/CLE.html\" title=\"Cleveland Cavaliers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">44</td><td class=\"right\" data-stat=\"losses\">38',\n",
       " '<a href=\"/contracts/ATL.html\" title=\"Atlanta Hawks Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">43</td><td class=\"right\" data-stat=\"losses\">39',\n",
       " '<a href=\"/contracts/CHO.html\" title=\"Charlotte Hornets Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">43</td><td class=\"right\" data-stat=\"losses\">39',\n",
       " '<a href=\"/contracts/NYK.html\" title=\"New York Knicks Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">37</td><td class=\"right\" data-stat=\"losses\">45',\n",
       " '<a href=\"/contracts/WAS.html\" title=\"Washington Wizards Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">35</td><td class=\"right\" data-stat=\"losses\">47',\n",
       " '<a href=\"/contracts/IND.html\" title=\"Indiana Pacers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">25</td><td class=\"right\" data-stat=\"losses\">57',\n",
       " '<a href=\"/contracts/DET.html\" title=\"Detroit Pistons Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">23</td><td class=\"right\" data-stat=\"losses\">59',\n",
       " '<a href=\"/contracts/ORL.html\" title=\"Orlando Magic Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">22</td><td class=\"right\" data-stat=\"losses\">60',\n",
       " '<a href=\"/contracts/PHO.html\" title=\"Phoenix Suns Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">64</td><td class=\"right\" data-stat=\"losses\">18',\n",
       " '<a href=\"/contracts/MEM.html\" title=\"Memphis Grizzlies Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">56</td><td class=\"right\" data-stat=\"losses\">26',\n",
       " '<a href=\"/contracts/GSW.html\" title=\"Golden State Warriors Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">53</td><td class=\"right\" data-stat=\"losses\">29',\n",
       " '<a href=\"/contracts/DAL.html\" title=\"Dallas Mavericks Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">52</td><td class=\"right\" data-stat=\"losses\">30',\n",
       " '<a href=\"/contracts/UTA.html\" title=\"Utah Jazz Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">49</td><td class=\"right\" data-stat=\"losses\">33',\n",
       " '<a href=\"/contracts/DEN.html\" title=\"Denver Nuggets Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">48</td><td class=\"right\" data-stat=\"losses\">34',\n",
       " '<a href=\"/contracts/MIN.html\" title=\"Minnesota Timberwolves Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">46</td><td class=\"right\" data-stat=\"losses\">36',\n",
       " '<a href=\"/contracts/LAC.html\" title=\"Los Angeles Clippers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">42</td><td class=\"right\" data-stat=\"losses\">40',\n",
       " '<a href=\"/contracts/NOP.html\" title=\"New Orleans Pelicans Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">36</td><td class=\"right\" data-stat=\"losses\">46',\n",
       " '<a href=\"/contracts/SAS.html\" title=\"San Antonio Spurs Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">34</td><td class=\"right\" data-stat=\"losses\">48',\n",
       " '<a href=\"/contracts/LAL.html\" title=\"Los Angeles Lakers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">33</td><td class=\"right\" data-stat=\"losses\">49',\n",
       " '<a href=\"/contracts/SAC.html\" title=\"Sacramento Kings Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">30</td><td class=\"right\" data-stat=\"losses\">52',\n",
       " '<a href=\"/contracts/POR.html\" title=\"Portland Trail Blazers Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">27</td><td class=\"right\" data-stat=\"losses\">55',\n",
       " '<a href=\"/contracts/OKC.html\" title=\"Oklahoma City Thunder Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">24</td><td class=\"right\" data-stat=\"losses\">58',\n",
       " '<a href=\"/contracts/HOU.html\" title=\"Houston Rockets Team Payroll\">$</a></td><td class=\"right\" data-stat=\"wins\">20</td><td class=\"right\" data-stat=\"losses\">62']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364764d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the team code and their full name into a dictionary\n",
    "dict_info = {i[20:23]:[re.findall(r'title=\"(.*) Team Payroll', i)[0], int(re.findall(r'data-stat=\"wins\">(.*)</', i)[0]), int(re.findall(r'data-stat=\"losses\">(.*)', i)[0])] for i in list_info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fdbb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the playoff data\n",
    "URL =\"https://www.basketball-reference.com/playoffs/NBA_2022.html\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup_body = str(soup.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3f8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the playoff team name\n",
    "list_playoff = list(set([i.split(\"html'>\")[1] for i in re.findall(r'data-stat=\"team\" >(.*?)</a></td><td', soup_body)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494a93f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Denver Nuggets',\n",
       " 'Chicago Bulls',\n",
       " 'Miami Heat',\n",
       " 'Memphis Grizzlies',\n",
       " 'Milwaukee Bucks',\n",
       " 'Atlanta Hawks',\n",
       " 'Utah Jazz',\n",
       " 'Dallas Mavericks',\n",
       " 'New Orleans Pelicans',\n",
       " 'Phoenix Suns',\n",
       " 'Minnesota Timberwolves',\n",
       " 'Brooklyn Nets',\n",
       " 'Golden State Warriors',\n",
       " 'Toronto Raptors',\n",
       " 'Boston Celtics',\n",
       " 'Philadelphia 76ers']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_playoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c685dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the team data into a data frame\n",
    "team_df = pd.DataFrame({'team': dict_info.keys(), 'name': [i[0] for i in dict_info.values()], 'win': [int(i[1]) for i in dict_info.values()], 'loss': [int(i[2]) for i in dict_info.values()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e131312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match all the playoff information with the data frame\n",
    "list_in_playoff = [1 if i in list_playoff else 0 for i in team_df.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee85a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column of  in_playoff into the data frame for team information\n",
    "team_df['in_playoff'] = list_in_playoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbeac4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the team information into spark data frame\n",
    "df_team = spark.createDataFrame(team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d20fec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- team: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- win: long (nullable = true)\n",
      " |-- loss: long (nullable = true)\n",
      " |-- in_playoff: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of the data frame\n",
    "df_team.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e3df17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data frame into parquet format\n",
    "df_team.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/team.parquet\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74b025",
   "metadata": {},
   "source": [
    "# players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80c33e",
   "metadata": {},
   "source": [
    "Firstly, load the team information data frame to get the initials for each team.\n",
    "\n",
    "Secondly, the new data frame for each players is created with the columns of 'team', 'playoff', 'name', 'link', 'No.', 'pos', 'height', 'weight', 'birth', 'age', 'exp', 'is_eastern'. Looping through each team page to get the basic information for each player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8ceca",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Column Name</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">team</td>\n",
    "    <td class=\"tg-0lax\">The team the player belongs to</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">playoff</td>\n",
    "    <td class=\"tg-0lax\">Whether this player is in a playoff team</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">name</td>\n",
    "    <td class=\"tg-0pky\">The name for each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">link</td>\n",
    "    <td class=\"tg-0pky\">The unique link for each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">No.</td>\n",
    "    <td class=\"tg-0pky\">The players number</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">pos</td>\n",
    "    <td class=\"tg-0pky\">The position the player is at in each team</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">height</td>\n",
    "    <td class=\"tg-0pky\">The height for each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">weight</td>\n",
    "    <td class=\"tg-0pky\"><span style=\"font-weight:400;font-style:normal\">The weight for each player</span></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">birth</td>\n",
    "    <td class=\"tg-0lax\">The year of birth for each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">age</td>\n",
    "    <td class=\"tg-0lax\">The age of each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">exp</td>\n",
    "    <td class=\"tg-0lax\">The year of experience for each player</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">is_eastern</td>\n",
    "    <td class=\"tg-0lax\">Whether this player is in a team in the eastern conference</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59493c",
   "metadata": {},
   "source": [
    "Thirdly, after all the player's links are taken from the team page, the complete version of their current season and career result are gathered using regular expressions. The team's contract link is used for getting the guaranteed data for each player. All the NaN are filled after this section of process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d6df928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the parquet file for team df\n",
    "team_df = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/team.parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c914370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame to store each player's information\n",
    "players = pd.DataFrame(columns = ['team', 'playoff', 'name', 'link', 'No.', 'pos', 'height', 'weight', 'birth', 'age', 'exp', 'is_eastern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "786ebfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>playoff</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>No.</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>birth</th>\n",
       "      <th>age</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_eastern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [team, playoff, name, link, No., pos, height, weight, birth, age, exp, is_eastern]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26d44583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through each team page and get all the players in each team and their related information\n",
    "for t in team_df.team:\n",
    "    URL =f\"https://www.basketball-reference.com/teams/{t}/2022.html\"\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    soup_body = str(soup.body)\n",
    "    \n",
    "    no = [i for i in re.findall(r'data-stat=\"number\" scope=\"row\">(.*)</th>', soup_body)]\n",
    "    link_name = [i.split('</a>')[0].split('\">') for i in re.findall(r'\"><a href=\"(.*?)data-stat=\"pos\"', soup_body)]\n",
    "    pos = re.findall(r'data-stat=\"pos\">(.*?)</td>', soup_body)\n",
    "    height = [float(i.replace('-', '.')) for i in re.findall(r'data-stat=\"height\">(.*?)</td>', soup_body)]\n",
    "    weight = [int(i) for i in re.findall(r'data-stat=\"weight\">(.*?)</td>', soup_body)]\n",
    "    birth = re.findall(r'</td><td class=\"left\" csk=\"(.*)\" data-stat=\"birth_date\">', soup_body)\n",
    "    exp = re.findall(r'data-stat=\"years_experience\">(.*)</td><td class', soup_body)\n",
    "    list_team = [t for i in range(len(no))]\n",
    "    playoff = team_df[team_df['team'] == t]['in_playoff'].values[0]\n",
    "    list_playoff_t = [int(playoff) for i in range(len(no))]\n",
    "    is_eastern = [1 if 'Eastern' in re.findall(r'>NBA</a> \\n(.*)\\n', soup_body)[0] else 0 for i in range(len(no))]\n",
    "    \n",
    "    players = players.append(pd.DataFrame({'team': list_team,'playoff': list_playoff_t, 'name': [i[1] for i in link_name], 'link': [i[0] for i in link_name], 'No.': no, 'pos': pos, 'height': height, 'weight': weight, 'birth':[int(i[:4]) for i in birth], 'exp': exp, 'is_eastern':is_eastern})).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15e76166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the experience information with 'R' to 0.5 and convert the data type into float64\n",
    "players['exp'] = players['exp'].replace('R', 0.5)\n",
    "players['exp'] = players['exp'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05e17fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# temporary lists for all the players' information\n",
    "temp_in_season = []\n",
    "temp_list_2122 = []\n",
    "temp_list_career = []\n",
    "# loop through each player's page and get their game information\n",
    "for count,l in enumerate(players.link):\n",
    "    URL =f\"https://www.basketball-reference.com{l}\"\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    soup_body = str(soup.body)\n",
    "    \n",
    "    \n",
    "    temp_in_season.append('gamelog/2022' in soup_body)\n",
    "    temp_list_2122.append(re.findall(fr'{l[1:-5]}/gamelog/2022\">(.*?)</td></tr> ', soup_body))\n",
    "    temp_list_career.append(re.findall(r'</tbody><tfoot><tr><th class=\"left\" data-stat=\"season\" scope=\"row\">Career(.*?)</td></tr>', soup_body))\n",
    "# add the columns into the players data frame\n",
    "players['in_2021_22_season'] = temp_in_season\n",
    "players['2021_2022_season'] = temp_list_2122\n",
    "players['career'] = temp_list_career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "140fae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "# loop through the teams and get each player's guarantee\n",
    "for t in team_df.team:\n",
    "    \n",
    "    URL =f\"https://www.basketball-reference.com/contracts/{t}.html\"\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    soup_body = str(soup.body)\n",
    "    for i in re.findall(r'data-stat=\"player\"(.*)</td></tr>', soup_body):\n",
    "        if '.html\">' in i and 'scope=\"row\"><em>' not in i:\n",
    "            temp_dict[re.findall(r'html\">(.*)</a>', i)[0]] = re.findall(r'data-stat=\"remain_gtd\">\\$(.*)', i)\n",
    "players = players.merge(pd.DataFrame({'name': temp_dict.keys(), 'guaranteed': temp_dict.values()}), how = 'left', on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9949609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all na\n",
    "players = players.replace((np.inf, -np.inf, np.nan), '0').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac0fbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list into int\n",
    "players['guaranteed'] = players['guaranteed'].apply(lambda x: int(x[0].replace(',','')) if len(x)>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "980c8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the age of each player by 2022-birth year\n",
    "players['age'] = players['birth'].apply(lambda x: 2022 - int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d00a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the empty information \n",
    "players['2021_2022_season'] = players['2021_2022_season'].apply(lambda x: x[0] if len(x) > 0 else '0')\n",
    "players['career'] = players['career'].apply(lambda x: x[0] if len(x) > 0 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d633f804",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>playoff</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>No.</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>birth</th>\n",
       "      <th>age</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_eastern</th>\n",
       "      <th>in_2021_22_season</th>\n",
       "      <th>2021_2022_season</th>\n",
       "      <th>career</th>\n",
       "      <th>guaranteed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Malik Beasley</td>\n",
       "      <td>/players/b/beaslma01.html</td>\n",
       "      <td>5</td>\n",
       "      <td>SG</td>\n",
       "      <td>6.40</td>\n",
       "      <td>187</td>\n",
       "      <td>1996</td>\n",
       "      <td>26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>29849999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Naz Reid</td>\n",
       "      <td>/players/r/reidna01.html</td>\n",
       "      <td>11</td>\n",
       "      <td>C</td>\n",
       "      <td>6.90</td>\n",
       "      <td>264</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>/players/t/townska01.html</td>\n",
       "      <td>32</td>\n",
       "      <td>C</td>\n",
       "      <td>6.11</td>\n",
       "      <td>248</td>\n",
       "      <td>1995</td>\n",
       "      <td>27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;span class=\"sr_star\"&gt;&lt;/span&gt;&lt;/th&gt;&lt;...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>101370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Jarred Vanderbilt</td>\n",
       "      <td>/players/v/vandeja01.html</td>\n",
       "      <td>8</td>\n",
       "      <td>PF</td>\n",
       "      <td>6.90</td>\n",
       "      <td>214</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>13800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Anthony Edwards</td>\n",
       "      <td>/players/e/edwaran01.html</td>\n",
       "      <td>1</td>\n",
       "      <td>SG</td>\n",
       "      <td>6.40</td>\n",
       "      <td>225</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>20978880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>/players/c/couside01.html</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>6.10</td>\n",
       "      <td>270</td>\n",
       "      <td>1990</td>\n",
       "      <td>32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>1138659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>Markus Howard</td>\n",
       "      <td>/players/h/howarma02.html</td>\n",
       "      <td>00</td>\n",
       "      <td>SG</td>\n",
       "      <td>5.10</td>\n",
       "      <td>175</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>Vlatko Čančar</td>\n",
       "      <td>/players/c/cancavl01.html</td>\n",
       "      <td>31</td>\n",
       "      <td>PF</td>\n",
       "      <td>6.80</td>\n",
       "      <td>236</td>\n",
       "      <td>1997</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael Porter Jr.</td>\n",
       "      <td>/players/p/portemi01.html</td>\n",
       "      <td>1</td>\n",
       "      <td>SF</td>\n",
       "      <td>6.10</td>\n",
       "      <td>218</td>\n",
       "      <td>1998</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2021-22&lt;/a&gt;&lt;/th&gt;&lt;td class=\"center\" data-stat=\"...</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>150538735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamal Murray</td>\n",
       "      <td>/players/m/murraja01.html</td>\n",
       "      <td></td>\n",
       "      <td>PG</td>\n",
       "      <td>6.30</td>\n",
       "      <td>215</td>\n",
       "      <td>1997</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;/th&gt;&lt;td class=\"center iz\" data-stat=\"age\"&gt;&lt;/t...</td>\n",
       "      <td>140400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    team  playoff                name                       link No. pos  \\\n",
       "0    MIN        1       Malik Beasley  /players/b/beaslma01.html   5  SG   \n",
       "1    MIN        1            Naz Reid   /players/r/reidna01.html  11   C   \n",
       "2    MIN        1  Karl-Anthony Towns  /players/t/townska01.html  32   C   \n",
       "3    MIN        1   Jarred Vanderbilt  /players/v/vandeja01.html   8  PF   \n",
       "4    MIN        1     Anthony Edwards  /players/e/edwaran01.html   1  SG   \n",
       "..   ...      ...                 ...                        ...  ..  ..   \n",
       "503  DEN        1    DeMarcus Cousins  /players/c/couside01.html   4   C   \n",
       "504  DEN        1       Markus Howard  /players/h/howarma02.html  00  SG   \n",
       "505  DEN        1       Vlatko Čančar  /players/c/cancavl01.html  31  PF   \n",
       "506  DEN        1  Michael Porter Jr.  /players/p/portemi01.html   1  SF   \n",
       "507  DEN        1        Jamal Murray  /players/m/murraja01.html      PG   \n",
       "\n",
       "     height  weight  birth  age   exp  is_eastern  in_2021_22_season  \\\n",
       "0      6.40     187   1996   26   5.0           0               True   \n",
       "1      6.90     264   1999   23   2.0           0               True   \n",
       "2      6.11     248   1995   27   6.0           0               True   \n",
       "3      6.90     214   1999   23   3.0           0               True   \n",
       "4      6.40     225   2001   21   1.0           0               True   \n",
       "..      ...     ...    ...  ...   ...         ...                ...   \n",
       "503    6.10     270   1990   32  10.0           0               True   \n",
       "504    5.10     175   1999   23   1.0           0               True   \n",
       "505    6.80     236   1997   25   2.0           0               True   \n",
       "506    6.10     218   1998   24   2.0           0               True   \n",
       "507    6.30     215   1997   25   5.0           0              False   \n",
       "\n",
       "                                      2021_2022_season  \\\n",
       "0    2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "1    2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "2    2021-22</a><span class=\"sr_star\"></span></th><...   \n",
       "3    2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "4    2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "..                                                 ...   \n",
       "503  2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "504  2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "505  2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "506  2021-22</a></th><td class=\"center\" data-stat=\"...   \n",
       "507                                                  0   \n",
       "\n",
       "                                                career  guaranteed  \n",
       "0    </th><td class=\"center iz\" data-stat=\"age\"></t...    29849999  \n",
       "1    </th><td class=\"center iz\" data-stat=\"age\"></t...           0  \n",
       "2    </th><td class=\"center iz\" data-stat=\"age\"></t...   101370000  \n",
       "3    </th><td class=\"center iz\" data-stat=\"age\"></t...    13800000  \n",
       "4    </th><td class=\"center iz\" data-stat=\"age\"></t...    20978880  \n",
       "..                                                 ...         ...  \n",
       "503  </th><td class=\"center iz\" data-stat=\"age\"></t...     1138659  \n",
       "504  </th><td class=\"center iz\" data-stat=\"age\"></t...           0  \n",
       "505  </th><td class=\"center iz\" data-stat=\"age\"></t...           0  \n",
       "506  </th><td class=\"center iz\" data-stat=\"age\"></t...   150538735  \n",
       "507  </th><td class=\"center iz\" data-stat=\"age\"></t...   140400000  \n",
       "\n",
       "[508 rows x 16 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6e914",
   "metadata": {},
   "source": [
    "Finally, the function *get_info* is written to return the specific score with its own pattern, therefore, it can be called straight away instead of writing repeated code several times.\n",
    "\n",
    "There are 16 columns of data selected for both the current season and the career scores from the original data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffeddca",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0lax\">Score type</th>\n",
    "    <th class=\"tg-0lax\">Description</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">G</td>\n",
    "    <td class=\"tg-0pky\">Games</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">GS</td>\n",
    "    <td class=\"tg-0pky\">Game Started</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">MP</td>\n",
    "    <td class=\"tg-0pky\">Minutes Played Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">FG%</td>\n",
    "    <td class=\"tg-0pky\">Field Goals Percent</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">3P%</td>\n",
    "    <td class=\"tg-0pky\">3 Points Percent</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">2P%</td>\n",
    "    <td class=\"tg-0pky\">2 Points Percent</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">eFG%</td>\n",
    "    <td class=\"tg-0pky\">Effective Field Goal Percent</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">FT%</td>\n",
    "    <td class=\"tg-0pky\">Free Through Percent</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">ORB</td>\n",
    "    <td class=\"tg-0pky\">Offensive Rebounds Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">DRB</td>\n",
    "    <td class=\"tg-0pky\">Defensive Rebounds Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">AST</td>\n",
    "    <td class=\"tg-0pky\">Assists Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">STL</td>\n",
    "    <td class=\"tg-0pky\">Steals Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky\">BLK</td>\n",
    "    <td class=\"tg-0pky\">Blocks Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">TOV</td>\n",
    "    <td class=\"tg-0lax\">Turnovers Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">PF</td>\n",
    "    <td class=\"tg-0lax\">Personal Fouls Per Game</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">PTS</td>\n",
    "    <td class=\"tg-0lax\">Points Per Game</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee86726",
   "metadata": {},
   "source": [
    "Each of the scores in the above table is generated by calling the get_info function for both the 2021-2022 season and the player's career results. The columns with the original information are dropped and the final data frame is converted into a spark data frame for checking the data type and it is converted into parquet files for further uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cec6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(pattern, list_info):\n",
    "    '''\n",
    "    function to get information for different attributes\n",
    "    '''\n",
    "    temp_list = []\n",
    "    for count, i in enumerate(list_info):\n",
    "        if i!='0':\n",
    "            result = re.findall(pattern, i)[0]\n",
    "            if 'strong' in result:\n",
    "                result = result.replace('strong','').replace('/','').replace('<','').replace('>','')\n",
    "            if result == '':\n",
    "                result = 0\n",
    "            \n",
    "            temp_list.append(result)\n",
    "        else:\n",
    "            temp_list.append(0)\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3d177c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new columns and get the corresponding information and convert the data type\n",
    "players['G_2122'] = get_info((r'data-stat=\"g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['G_2122'] = players['G_2122'].astype(np.int64)\n",
    "players['GS_2122'] = get_info((r'data-stat=\"gs\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['GS_2122'] = players['GS_2122'].astype(np.int64)\n",
    "players['MP_2122'] = get_info((r'data-stat=\"mp_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['MP_2122'] = players['MP_2122'].astype(np.float64)\n",
    "players['FG%_2122'] = get_info((r'data-stat=\"fg_pct\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['FG%_2122'] = players['FG%_2122'].astype(np.float64)\n",
    "players['3P%_2122'] = get_info((r'data-stat=\"fg3_pct\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['3P%_2122'] = players['3P%_2122'].astype(np.float64)\n",
    "players['2P%_2122'] = get_info((r'data-stat=\"fg2_pct\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['2P%_2122'] = players['2P%_2122'].astype(np.float64)\n",
    "players['eFG%_2122'] = get_info((r'data-stat=\"efg_pct\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['eFG%_2122'] = players['eFG%_2122'].astype(np.float64)\n",
    "players['FT%_2122'] = get_info((r'data-stat=\"ft_pct\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['FT%_2122'] = players['FT%_2122'].astype(np.float64)\n",
    "players['ORB_2122'] = get_info((r'data-stat=\"orb_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['ORB_2122'] = players['ORB_2122'].astype(np.float64)\n",
    "players['DRB_2122'] = get_info((r'data-stat=\"drb_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['DRB_2122'] = players['DRB_2122'].astype(np.float64)\n",
    "players['AST_2122'] = get_info((r'data-stat=\"ast_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['AST_2122'] = players['AST_2122'].astype(np.float64)\n",
    "players['STL_2122'] = get_info((r'data-stat=\"stl_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['STL_2122'] = players['STL_2122'].astype(np.float64)\n",
    "players['BLK_2122'] = get_info((r'data-stat=\"blk_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['BLK_2122'] = players['BLK_2122'].astype(np.float64)\n",
    "players['TOV_2122'] = get_info((r'data-stat=\"tov_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['TOV_2122'] = players['TOV_2122'].astype(np.float64)\n",
    "players['PF_2122'] = get_info((r'data-stat=\"pf_per_g\">(.*?)</td'), players['2021_2022_season'])\n",
    "players['PF_2122'] = players['PF_2122'].astype(np.float64)\n",
    "players['PTS_2122'] = get_info((r'data-stat=\"pts_per_g\">(.*)'), players['2021_2022_season'])\n",
    "players['PTS_2122'] = players['PTS_2122'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cefc5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns and get the corresponding information and convert the data type\n",
    "players['G_career'] = get_info((r'data-stat=\"g\">(.*?)</td'), players['career'])\n",
    "players['G_career'] = players['G_career'].astype(np.int64)\n",
    "players['GS_career'] = get_info((r'data-stat=\"gs\">(.*?)</td'), players['career'])\n",
    "players['GS_career'] = players['GS_career'].astype(np.int64)\n",
    "players['MP_career'] = get_info((r'data-stat=\"mp_per_g\">(.*?)</td'), players['career'])\n",
    "players['MP_career'] = players['MP_career'].astype(np.float64)\n",
    "players['FG%_career'] = get_info((r'data-stat=\"fg_pct\">(.*?)</td'), players['career'])\n",
    "players['FG%_career'] = players['FG%_career'].astype(np.float64)\n",
    "players['3P%_career'] = get_info((r'data-stat=\"fg3_pct\">(.*?)</td'), players['career'])\n",
    "players['3P%_career'] = players['3P%_career'].astype(np.float64)\n",
    "players['2P%_career'] = get_info((r'data-stat=\"fg2_pct\">(.*?)</td'), players['career'])\n",
    "players['2P%_career'] = players['2P%_career'].astype(np.float64)\n",
    "players['eFG%_career'] = get_info((r'data-stat=\"efg_pct\">(.*?)</td'), players['career'])\n",
    "players['eFG%_career'] = players['eFG%_career'].astype(np.float64)\n",
    "players['FT%_career'] = get_info((r'data-stat=\"ft_pct\">(.*?)</td'), players['career'])\n",
    "players['FT%_career'] = players['FT%_career'].astype(np.float64)\n",
    "players['ORB_career'] = get_info((r'data-stat=\"orb_per_g\">(.*?)</td'), players['career'])\n",
    "players['ORB_career'] = players['ORB_career'].astype(np.float64)\n",
    "players['DRB_career'] = get_info((r'data-stat=\"drb_per_g\">(.*?)</td'), players['career'])\n",
    "players['DRB_career'] = players['DRB_career'].astype(np.float64)\n",
    "players['AST_career'] = get_info((r'data-stat=\"ast_per_g\">(.*?)</td'), players['career'])\n",
    "players['AST_career'] = players['AST_career'].astype(np.float64)\n",
    "players['STL_career'] = get_info((r'data-stat=\"stl_per_g\">(.*?)</td'), players['career'])\n",
    "players['STL_career'] = players['STL_career'].astype(np.float64)\n",
    "players['BLK_career'] = get_info((r'data-stat=\"blk_per_g\">(.*?)</td'), players['career'])\n",
    "players['BLK_career'] = players['BLK_career'].astype(np.float64)\n",
    "players['TOV_career'] = get_info((r'data-stat=\"tov_per_g\">(.*?)</td'), players['career'])\n",
    "players['TOV_career'] = players['TOV_career'].astype(np.float64)\n",
    "players['PF_career'] = get_info((r'data-stat=\"pf_per_g\">(.*?)</td'), players['career'])\n",
    "players['PF_career'] = players['PF_career'].astype(np.float64)\n",
    "players['PTS_career'] = get_info((r'data-stat=\"pts_per_g\">(.*)'), players['career'])\n",
    "players['PTS_career'] = players['PTS_career'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adcf3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = players.drop(['2021_2022_season', 'career'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dcf3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the players data into spark data frame\n",
    "players_df = spark.createDataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a578dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- team: string (nullable = true)\n",
      " |-- playoff: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- No.: string (nullable = true)\n",
      " |-- pos: string (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      " |-- birth: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- exp: double (nullable = true)\n",
      " |-- is_eastern: long (nullable = true)\n",
      " |-- in_2021_22_season: boolean (nullable = true)\n",
      " |-- guaranteed: long (nullable = true)\n",
      " |-- G_2122: long (nullable = true)\n",
      " |-- GS_2122: long (nullable = true)\n",
      " |-- MP_2122: double (nullable = true)\n",
      " |-- FG%_2122: double (nullable = true)\n",
      " |-- 3P%_2122: double (nullable = true)\n",
      " |-- 2P%_2122: double (nullable = true)\n",
      " |-- eFG%_2122: double (nullable = true)\n",
      " |-- FT%_2122: double (nullable = true)\n",
      " |-- ORB_2122: double (nullable = true)\n",
      " |-- DRB_2122: double (nullable = true)\n",
      " |-- AST_2122: double (nullable = true)\n",
      " |-- STL_2122: double (nullable = true)\n",
      " |-- BLK_2122: double (nullable = true)\n",
      " |-- TOV_2122: double (nullable = true)\n",
      " |-- PF_2122: double (nullable = true)\n",
      " |-- PTS_2122: double (nullable = true)\n",
      " |-- G_career: long (nullable = true)\n",
      " |-- GS_career: long (nullable = true)\n",
      " |-- MP_career: double (nullable = true)\n",
      " |-- FG%_career: double (nullable = true)\n",
      " |-- 3P%_career: double (nullable = true)\n",
      " |-- 2P%_career: double (nullable = true)\n",
      " |-- eFG%_career: double (nullable = true)\n",
      " |-- FT%_career: double (nullable = true)\n",
      " |-- ORB_career: double (nullable = true)\n",
      " |-- DRB_career: double (nullable = true)\n",
      " |-- AST_career: double (nullable = true)\n",
      " |-- STL_career: double (nullable = true)\n",
      " |-- BLK_career: double (nullable = true)\n",
      " |-- TOV_career: double (nullable = true)\n",
      " |-- PF_career: double (nullable = true)\n",
      " |-- PTS_career: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of the spark data frame\n",
    "players_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "917030ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the data frame into parquet format\n",
    "players_df.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/players.parquet\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b968f5",
   "metadata": {},
   "source": [
    "# prepare the data for ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27ed0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f1c3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from parquet file\n",
    "players = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/players.parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b8e1ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the categorecal data into dummies\n",
    "dummies_df = pd.get_dummies(players['pos'], prefix='is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "716602ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the columns into the data frame\n",
    "for c in dummies_df.columns:\n",
    "    players[c] = list(dummies_df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a648b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from True/False to 1/0\n",
    "players['in_2021_22_season'] = players['in_2021_22_season'].replace({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ae12cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = players.sort_values('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c602f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not used for machine learning\n",
    "players = players.drop([ 'team', 'name', 'link', 'pos', 'No.'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02505c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# load the yaml document\n",
    "params = yaml.safe_load(open(\"/project/MSIN0166_Data_Engineering_individual/params.yaml\"))[\"ML\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7fae605f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split': 0.2, 'seed': 42, 'shuffle': True, 'n_components': 10}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c8cbf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark df\n",
    "players_df  = spark.createDataFrame(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d652443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train and test sets\n",
    "players_train, players_test  = players_df.randomSplit([1-params['split'],params['split']],seed=params['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a0238cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns for pca\n",
    "players_train_trans = players_train.select(players_train.columns[9:-5])\n",
    "players_test_trans = players_test.select(players_test.columns[9:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a81ef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_train_trans.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8785b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# assemble the training data first\n",
    "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in players_train_trans.columns]\n",
    "# standerdise the data\n",
    "scaler = [StandardScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in players_train_trans.columns]\n",
    "pipeline = Pipeline(stages= assemblers + scaler)\n",
    "X_train = pipeline.fit(players_train_trans)\n",
    "X_train = X_train.transform(players_train_trans)\n",
    "\n",
    "\n",
    "# assemble the testing data\n",
    "assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in players_test_trans.columns]\n",
    "# standerdise the data\n",
    "scaler = [StandardScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in players_test_trans.columns]\n",
    "pipeline = Pipeline(stages= assemblers + scaler)\n",
    "X_test = pipeline.fit(players_test_trans)\n",
    "X_test = X_test.transform(players_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c4cb0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scaled columns\n",
    "columns = [i for i in X_train.columns if 'scaled' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eade4a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G_2122_scaled',\n",
       " 'GS_2122_scaled',\n",
       " 'MP_2122_scaled',\n",
       " 'FG%_2122_scaled',\n",
       " '3P%_2122_scaled',\n",
       " '2P%_2122_scaled',\n",
       " 'eFG%_2122_scaled',\n",
       " 'FT%_2122_scaled',\n",
       " 'ORB_2122_scaled',\n",
       " 'DRB_2122_scaled',\n",
       " 'AST_2122_scaled',\n",
       " 'STL_2122_scaled',\n",
       " 'BLK_2122_scaled',\n",
       " 'TOV_2122_scaled',\n",
       " 'PF_2122_scaled',\n",
       " 'PTS_2122_scaled',\n",
       " 'G_career_scaled',\n",
       " 'GS_career_scaled',\n",
       " 'MP_career_scaled',\n",
       " 'FG%_career_scaled',\n",
       " '3P%_career_scaled',\n",
       " '2P%_career_scaled',\n",
       " 'eFG%_career_scaled',\n",
       " 'FT%_career_scaled',\n",
       " 'ORB_career_scaled',\n",
       " 'DRB_career_scaled',\n",
       " 'AST_career_scaled',\n",
       " 'STL_career_scaled',\n",
       " 'BLK_career_scaled',\n",
       " 'TOV_career_scaled',\n",
       " 'PF_career_scaled',\n",
       " 'PTS_career_scaled']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c3f98ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "# assemble the columns into features column\n",
    "assemblers = VectorAssembler(inputCols= ['G_2122_scaled',\n",
    " 'GS_2122_scaled',\n",
    " 'MP_2122_scaled',\n",
    " 'FG%_2122_scaled',\n",
    " '3P%_2122_scaled',\n",
    " '2P%_2122_scaled',\n",
    " 'eFG%_2122_scaled',\n",
    " 'FT%_2122_scaled',\n",
    " 'ORB_2122_scaled',\n",
    " 'DRB_2122_scaled',\n",
    " 'AST_2122_scaled',\n",
    " 'STL_2122_scaled',\n",
    " 'BLK_2122_scaled',\n",
    " 'TOV_2122_scaled',\n",
    " 'PF_2122_scaled',\n",
    " 'PTS_2122_scaled',\n",
    " 'G_career_scaled',\n",
    " 'GS_career_scaled',\n",
    " 'MP_career_scaled',\n",
    " 'FG%_career_scaled',\n",
    " '3P%_career_scaled',\n",
    " '2P%_career_scaled',\n",
    " 'eFG%_career_scaled',\n",
    " 'FT%_career_scaled',\n",
    " 'ORB_career_scaled',\n",
    " 'DRB_career_scaled',\n",
    " 'AST_career_scaled',\n",
    " 'STL_career_scaled',\n",
    " 'BLK_career_scaled',\n",
    " 'TOV_career_scaled',\n",
    " 'PF_career_scaled',\n",
    " 'PTS_career_scaled'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "98421a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data and return the PCA result in the column of PCA_features\n",
    "X_train_v = assemblers.transform(X_train)\n",
    "PCA_train = PCA(k = 10, inputCol=\"features\", outputCol = 'PCA_features')\n",
    "\n",
    "X_train_model = PCA_train.fit(X_train_v)\n",
    "X_train = X_train_model.transform(X_train_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e64c1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the testing data and return the PCA result in the column of PCA_features\n",
    "X_test_v = assemblers.transform(X_test)\n",
    "PCA_test = PCA(k = 10, inputCol=\"features\", outputCol = 'PCA_features')\n",
    "\n",
    "X_test_model = PCA_test.fit(X_test_v)\n",
    "X_test = X_test_model.transform(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe47d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 98)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "10371eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9084743306139076"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_train_model.explainedVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ff1f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the PCA variation\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.plot(np.cumsum(X_train_model.explainedVariance),linestyle='solid', marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Variation explained by PCA')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b3250dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nonPCA columns\n",
    "players_train_first = players_train.select(list(set(players_train.columns[:9]) | set(players_train.columns[-5:])))\n",
    "players_test_first = players_test.select(list(set(players_test.columns[:9]) | set(players_test.columns[-5:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac931043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the PCA result column into data frame\n",
    "temp_train = X_train.select('PCA_features').rdd.map(lambda x: [float(i) for i in x['PCA_features']]).toDF(['PCA' + str(i+1) for i in range(10)])\n",
    "temp_test = X_test.select('PCA_features').rdd.map(lambda x: [float(i) for i in x['PCA_features']]).toDF(['PCA' + str(i+1) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9cc044b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to pandas\n",
    "players_train_first_pd = players_train_first.toPandas()\n",
    "players_test_first_pd = players_test_first.toPandas()\n",
    "temp_train_pd = temp_train.toPandas()\n",
    "temp_test_pd = temp_test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fc5b30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the columns together\n",
    "for c in temp_train_pd.columns:\n",
    "    players_train_first_pd[c] = temp_train_pd[c]\n",
    "for c in temp_test_pd.columns:\n",
    "    players_test_first_pd[c] = temp_test_pd[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "013f0920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to spark df\n",
    "players_train_final = spark.createDataFrame(players_train_first_pd)\n",
    "players_test_final = spark.createDataFrame(players_test_first_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c63d1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "59419a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble all the X columns into features\n",
    "assembler = VectorAssembler(inputCols =['is_PG',\n",
    " 'is_SF',\n",
    " 'is_SG',\n",
    " 'is_eastern',\n",
    " 'height',\n",
    " 'guaranteed',\n",
    " 'is_PF',\n",
    " 'age',\n",
    " 'birth',\n",
    " 'is_C',\n",
    " 'weight',\n",
    " 'in_2021_22_season',\n",
    " 'exp',\n",
    " 'PCA1',\n",
    " 'PCA2',\n",
    " 'PCA3',\n",
    " 'PCA4',\n",
    " 'PCA5',\n",
    " 'PCA6',\n",
    " 'PCA7',\n",
    " 'PCA8',\n",
    " 'PCA9',\n",
    " 'PCA10'] , outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9fa4cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test data\n",
    "players_train_final = assembler.transform(players_train_final)\n",
    "players_test_final= assembler.transform(players_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c7ffb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column playoff to label\n",
    "players_train_final = players_train_final.withColumnRenamed('playoff', 'label')\n",
    "players_test_final= players_test_final.withColumnRenamed('playoff', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0bddd3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 25)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_train_final.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa0a556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and make the prediction\n",
    "clf_dt= DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "clf_dt = clf_dt.fit(players_train_final)\n",
    "pred_clf_dt = clf_dt.transform(players_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a97b70f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5794941790445605\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(pred_clf_dt)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37bda858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1b102046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[32 20]\n",
      " [22 26]]\n"
     ]
    }
   ],
   "source": [
    "y_p=pred_clf_dt.select(\"prediction\").collect()\n",
    "y =pred_clf_dt.select(\"label\").collect()\n",
    "\n",
    "cm = confusion_matrix(y, y_p)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7402fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (tn+tp)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "99d28f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# write the metrics into the scores.json file\n",
    "with open('/project/MSIN0166_Data_Engineering_individual/scores.json', \"w\") as fd:\n",
    "    json.dump({\"Accuract\":acc , 'Precision':precision, 'Recall': recall, 'F1_Score':2*((precision * recall)/(precision + recall))}, fd, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c67832",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb37feac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "teams = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/team.parquet\").toPandas()\n",
    "players = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/players.parquet\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54783aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>playoff</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>No.</th>\n",
       "      <th>pos</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>birth</th>\n",
       "      <th>age</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_eastern</th>\n",
       "      <th>in_2021_22_season</th>\n",
       "      <th>guaranteed</th>\n",
       "      <th>G_2122</th>\n",
       "      <th>GS_2122</th>\n",
       "      <th>MP_2122</th>\n",
       "      <th>FG%_2122</th>\n",
       "      <th>3P%_2122</th>\n",
       "      <th>2P%_2122</th>\n",
       "      <th>eFG%_2122</th>\n",
       "      <th>FT%_2122</th>\n",
       "      <th>ORB_2122</th>\n",
       "      <th>DRB_2122</th>\n",
       "      <th>AST_2122</th>\n",
       "      <th>STL_2122</th>\n",
       "      <th>BLK_2122</th>\n",
       "      <th>TOV_2122</th>\n",
       "      <th>PF_2122</th>\n",
       "      <th>PTS_2122</th>\n",
       "      <th>G_career</th>\n",
       "      <th>GS_career</th>\n",
       "      <th>MP_career</th>\n",
       "      <th>FG%_career</th>\n",
       "      <th>3P%_career</th>\n",
       "      <th>2P%_career</th>\n",
       "      <th>eFG%_career</th>\n",
       "      <th>FT%_career</th>\n",
       "      <th>ORB_career</th>\n",
       "      <th>DRB_career</th>\n",
       "      <th>AST_career</th>\n",
       "      <th>STL_career</th>\n",
       "      <th>BLK_career</th>\n",
       "      <th>TOV_career</th>\n",
       "      <th>PF_career</th>\n",
       "      <th>PTS_career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Nic Claxton</td>\n",
       "      <td>/players/c/claxtni01.html</td>\n",
       "      <td>33</td>\n",
       "      <td>C</td>\n",
       "      <td>6.11</td>\n",
       "      <td>215</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1782621</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Day'Ron Sharpe</td>\n",
       "      <td>/players/s/sharpda01.html</td>\n",
       "      <td>20</td>\n",
       "      <td>PF</td>\n",
       "      <td>6.11</td>\n",
       "      <td>265</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4118400</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.585</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.585</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>/players/i/irvinky01.html</td>\n",
       "      <td>11</td>\n",
       "      <td>PG</td>\n",
       "      <td>6.20</td>\n",
       "      <td>195</td>\n",
       "      <td>1992</td>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34916200</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>27.4</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>/players/d/drumman01.html</td>\n",
       "      <td>0, 4</td>\n",
       "      <td>C</td>\n",
       "      <td>6.10</td>\n",
       "      <td>279</td>\n",
       "      <td>1993</td>\n",
       "      <td>29</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2401537</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.524</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>718</td>\n",
       "      <td>630</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.473</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>David Duke Jr.</td>\n",
       "      <td>/players/d/dukeda01.html</td>\n",
       "      <td>6</td>\n",
       "      <td>PG</td>\n",
       "      <td>6.50</td>\n",
       "      <td>205</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Cam Thomas</td>\n",
       "      <td>/players/t/thomaca02.html</td>\n",
       "      <td>24</td>\n",
       "      <td>SG</td>\n",
       "      <td>6.40</td>\n",
       "      <td>210</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4174440</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>/players/g/griffbl01.html</td>\n",
       "      <td>2</td>\n",
       "      <td>PF</td>\n",
       "      <td>6.90</td>\n",
       "      <td>250</td>\n",
       "      <td>1989</td>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2641691</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.724</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>724</td>\n",
       "      <td>676</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>/players/d/duranke01.html</td>\n",
       "      <td>7</td>\n",
       "      <td>PF</td>\n",
       "      <td>6.10</td>\n",
       "      <td>240</td>\n",
       "      <td>1988</td>\n",
       "      <td>34</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>229997220</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>939</td>\n",
       "      <td>936</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>Kessler Edwards</td>\n",
       "      <td>/players/e/edwarke02.html</td>\n",
       "      <td>14</td>\n",
       "      <td>SF</td>\n",
       "      <td>6.80</td>\n",
       "      <td>215</td>\n",
       "      <td>2000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5318</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>BRK</td>\n",
       "      <td>1</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>/players/a/aldrila01.html</td>\n",
       "      <td>21</td>\n",
       "      <td>C</td>\n",
       "      <td>6.11</td>\n",
       "      <td>250</td>\n",
       "      <td>1985</td>\n",
       "      <td>37</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2641691</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.873</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1076</td>\n",
       "      <td>997</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.813</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    team  playoff               name                       link   No. pos  \\\n",
       "0    BRK        1        Nic Claxton  /players/c/claxtni01.html    33   C   \n",
       "1    BRK        1     Day'Ron Sharpe  /players/s/sharpda01.html    20  PF   \n",
       "2    BRK        1       Kyrie Irving  /players/i/irvinky01.html    11  PG   \n",
       "3    BRK        1     Andre Drummond  /players/d/drumman01.html  0, 4   C   \n",
       "4    BRK        1     David Duke Jr.   /players/d/dukeda01.html     6  PG   \n",
       "..   ...      ...                ...                        ...   ...  ..   \n",
       "503  BRK        1         Cam Thomas  /players/t/thomaca02.html    24  SG   \n",
       "504  BRK        1      Blake Griffin  /players/g/griffbl01.html     2  PF   \n",
       "505  BRK        1       Kevin Durant  /players/d/duranke01.html     7  PF   \n",
       "506  BRK        1    Kessler Edwards  /players/e/edwarke02.html    14  SF   \n",
       "507  BRK        1  LaMarcus Aldridge  /players/a/aldrila01.html    21   C   \n",
       "\n",
       "     height  weight  birth  age   exp  is_eastern  in_2021_22_season  \\\n",
       "0      6.11     215   1999   23   2.0           1               True   \n",
       "1      6.11     265   2001   21   0.5           1               True   \n",
       "2      6.20     195   1992   30  10.0           1               True   \n",
       "3      6.10     279   1993   29   9.0           1               True   \n",
       "4      6.50     205   1999   23   0.5           1               True   \n",
       "..      ...     ...    ...  ...   ...         ...                ...   \n",
       "503    6.40     210   2001   21   0.5           1               True   \n",
       "504    6.90     250   1989   33  11.0           1               True   \n",
       "505    6.10     240   1988   34  13.0           1               True   \n",
       "506    6.80     215   2000   22   0.5           1               True   \n",
       "507    6.11     250   1985   37  15.0           1               True   \n",
       "\n",
       "     guaranteed  G_2122  GS_2122  MP_2122  FG%_2122  3P%_2122  2P%_2122  \\\n",
       "0       1782621      47       19     20.7     0.674     0.000     0.674   \n",
       "1       4118400      32        8     12.2     0.577     0.286     0.592   \n",
       "2      34916200      29       29     37.6     0.469     0.418     0.501   \n",
       "3       2401537      73       36     19.7     0.570     0.000     0.574   \n",
       "4             0      22        7     15.5     0.361     0.243     0.423   \n",
       "..          ...     ...      ...      ...       ...       ...       ...   \n",
       "503     4174440      67        2     17.6     0.433     0.270     0.520   \n",
       "504     2641691      56       24     17.1     0.425     0.262     0.565   \n",
       "505   229997220      55       55     37.2     0.518     0.383     0.568   \n",
       "506        5318      48       23     20.6     0.412     0.353     0.473   \n",
       "507     2641691      47       12     22.3     0.550     0.304     0.578   \n",
       "\n",
       "     eFG%_2122  FT%_2122  ORB_2122  DRB_2122  AST_2122  STL_2122  BLK_2122  \\\n",
       "0        0.674     0.581       1.9       3.7       0.9       0.5       1.1   \n",
       "1        0.584     0.585       2.5       2.5       0.5       0.3       0.5   \n",
       "2        0.550     0.915       0.6       3.8       5.8       1.4       0.6   \n",
       "3        0.570     0.524       3.1       6.2       1.8       1.1       0.9   \n",
       "4        0.403     0.810       1.4       1.7       0.8       0.6       0.3   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "503      0.480     0.829       0.2       2.2       1.2       0.5       0.1   \n",
       "504      0.486     0.724       1.1       3.0       1.9       0.5       0.3   \n",
       "505      0.570     0.910       0.5       6.9       6.4       0.9       0.9   \n",
       "506      0.502     0.842       0.9       2.7       0.6       0.6       0.5   \n",
       "507      0.566     0.873       1.6       3.9       0.9       0.3       1.0   \n",
       "\n",
       "     TOV_2122  PF_2122  PTS_2122  G_career  GS_career  MP_career  FG%_career  \\\n",
       "0         0.8      2.3       8.7        94         20       18.7       0.646   \n",
       "1         0.9      1.9       6.2        32          8       12.2       0.577   \n",
       "2         2.5      2.8      27.4       611        611       34.0       0.470   \n",
       "3         1.6      2.6       7.9       718        630       29.6       0.540   \n",
       "4         0.4      1.6       4.7        22          7       15.5       0.361   \n",
       "..        ...      ...       ...       ...        ...        ...         ...   \n",
       "503       0.8      1.0       8.5        67          2       17.6       0.433   \n",
       "504       0.6      1.7       6.4       724        676       32.9       0.493   \n",
       "505       3.5      2.1      29.9       939        936       36.8       0.496   \n",
       "506       0.9      1.8       5.9        48         23       20.6       0.412   \n",
       "507       0.9      1.7      12.9      1076        997       33.7       0.493   \n",
       "\n",
       "     3P%_career  2P%_career  eFG%_career  FT%_career  ORB_career  DRB_career  \\\n",
       "0         0.167       0.658        0.648       0.539         1.6         3.4   \n",
       "1         0.286       0.592        0.584       0.585         2.5         2.5   \n",
       "2         0.393       0.505        0.532       0.882         0.8         3.1   \n",
       "3         0.132       0.546        0.541       0.473         4.5         8.7   \n",
       "4         0.243       0.423        0.403       0.810         1.4         1.7   \n",
       "..          ...         ...          ...         ...         ...         ...   \n",
       "503       0.270       0.520        0.480       0.829         0.2         2.2   \n",
       "504       0.327       0.521        0.517       0.696         2.0         6.2   \n",
       "505       0.384       0.536        0.546       0.884         0.7         6.4   \n",
       "506       0.353       0.473        0.502       0.842         0.9         2.7   \n",
       "507       0.320       0.500        0.499       0.813         2.6         5.5   \n",
       "\n",
       "     AST_career  STL_career  BLK_career  TOV_career  PF_career  PTS_career  \n",
       "0           0.9         0.5         1.1         0.7        2.0         7.3  \n",
       "1           0.5         0.3         0.5         0.9        1.9         6.2  \n",
       "2           5.7         1.3         0.4         2.6        2.3        23.1  \n",
       "3           1.4         1.4         1.5         2.0        3.1        13.8  \n",
       "4           0.8         0.6         0.3         0.4        1.6         4.7  \n",
       "..          ...         ...         ...         ...        ...         ...  \n",
       "503         1.2         0.5         0.1         0.8        1.0         8.5  \n",
       "504         4.1         0.8         0.5         2.4        2.7        19.8  \n",
       "505         4.3         1.1         1.1         3.2        1.9        27.2  \n",
       "506         0.6         0.6         0.5         0.9        1.8         5.9  \n",
       "507         1.9         0.7         1.1         1.5        2.4        19.1  \n",
       "\n",
       "[508 rows x 46 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3832bb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the team_code and thier conference area\n",
    "dict_team = {i:j for i,j in zip(players['team'], players['is_eastern'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c11248a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the area information with the team data frame\n",
    "teams_t = teams.merge(pd.DataFrame({'team':dict_team.keys(), 'is_eastern': dict_team.values()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6c02ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns name\n",
    "teams_t.columns = ['team_code', 'team_name', 'wins', 'loss', 'playoff', 'is_eastern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54659e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_code</th>\n",
       "      <th>team_name</th>\n",
       "      <th>wins</th>\n",
       "      <th>loss</th>\n",
       "      <th>playoff</th>\n",
       "      <th>is_eastern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIN</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAC</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOP</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAS</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAL</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SAC</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POR</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OKC</td>\n",
       "      <td>Oklahoma City Thunder</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOU</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHO</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NYK</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IND</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DET</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MIL</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PHI</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TOR</td>\n",
       "      <td>Toronto Raptors</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BRK</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PHO</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MEM</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GSW</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UTA</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_code               team_name  wins  loss  playoff  is_eastern\n",
       "0        MIN  Minnesota Timberwolves    46    36        1           0\n",
       "1        LAC    Los Angeles Clippers    42    40        0           0\n",
       "2        NOP    New Orleans Pelicans    36    46        1           0\n",
       "3        SAS       San Antonio Spurs    34    48        0           0\n",
       "4        LAL      Los Angeles Lakers    33    49        0           0\n",
       "5        SAC        Sacramento Kings    30    52        0           0\n",
       "6        POR  Portland Trail Blazers    27    55        0           0\n",
       "7        OKC   Oklahoma City Thunder    24    58        0           0\n",
       "8        HOU         Houston Rockets    20    62        0           0\n",
       "9        CLE     Cleveland Cavaliers    44    38        0           1\n",
       "10       ATL           Atlanta Hawks    43    39        1           1\n",
       "11       CHO       Charlotte Hornets    43    39        0           1\n",
       "12       NYK         New York Knicks    37    45        0           1\n",
       "13       WAS      Washington Wizards    35    47        0           1\n",
       "14       IND          Indiana Pacers    25    57        0           1\n",
       "15       DET         Detroit Pistons    23    59        0           1\n",
       "16       MIA              Miami Heat    53    29        1           1\n",
       "17       BOS          Boston Celtics    51    31        1           1\n",
       "18       MIL         Milwaukee Bucks    51    31        1           1\n",
       "19       PHI      Philadelphia 76ers    51    31        1           1\n",
       "20       TOR         Toronto Raptors    48    34        1           1\n",
       "21       CHI           Chicago Bulls    46    36        1           1\n",
       "22       BRK           Brooklyn Nets    44    38        1           1\n",
       "23       ORL           Orlando Magic    22    60        0           1\n",
       "24       PHO            Phoenix Suns    64    18        1           0\n",
       "25       MEM       Memphis Grizzlies    56    26        1           0\n",
       "26       GSW   Golden State Warriors    53    29        1           0\n",
       "27       DAL        Dallas Mavericks    52    30        1           0\n",
       "28       UTA               Utah Jazz    49    33        1           0\n",
       "29       DEN          Denver Nuggets    48    34        1           0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4be581c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the information for players table in the database\n",
    "players_t = players[['link', 'name', 'team', 'birth', 'age', 'No.', 'pos', 'guaranteed', 'height', 'weight', 'exp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd573f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns name\n",
    "players_t.columns = ['id', 'name', 'team_code', 'birth_year', 'age', 'number', 'possition', 'guaranteed', 'height', 'weight', 'exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45f8d4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>team_code</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "      <th>number</th>\n",
       "      <th>possition</th>\n",
       "      <th>guaranteed</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/players/c/claxtni01.html</td>\n",
       "      <td>Nic Claxton</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>C</td>\n",
       "      <td>1782621</td>\n",
       "      <td>6.11</td>\n",
       "      <td>215</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/players/s/sharpda01.html</td>\n",
       "      <td>Day'Ron Sharpe</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>PF</td>\n",
       "      <td>4118400</td>\n",
       "      <td>6.11</td>\n",
       "      <td>265</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/players/i/irvinky01.html</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1992</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>PG</td>\n",
       "      <td>34916200</td>\n",
       "      <td>6.20</td>\n",
       "      <td>195</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/players/d/drumman01.html</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1993</td>\n",
       "      <td>29</td>\n",
       "      <td>0, 4</td>\n",
       "      <td>C</td>\n",
       "      <td>2401537</td>\n",
       "      <td>6.10</td>\n",
       "      <td>279</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/players/d/dukeda01.html</td>\n",
       "      <td>David Duke Jr.</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1999</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>PG</td>\n",
       "      <td>0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>205</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>/players/t/thomaca02.html</td>\n",
       "      <td>Cam Thomas</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2001</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>SG</td>\n",
       "      <td>4174440</td>\n",
       "      <td>6.40</td>\n",
       "      <td>210</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>/players/g/griffbl01.html</td>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1989</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>PF</td>\n",
       "      <td>2641691</td>\n",
       "      <td>6.90</td>\n",
       "      <td>250</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>/players/d/duranke01.html</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1988</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>PF</td>\n",
       "      <td>229997220</td>\n",
       "      <td>6.10</td>\n",
       "      <td>240</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>/players/e/edwarke02.html</td>\n",
       "      <td>Kessler Edwards</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2000</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>SF</td>\n",
       "      <td>5318</td>\n",
       "      <td>6.80</td>\n",
       "      <td>215</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/players/a/aldrila01.html</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1985</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>C</td>\n",
       "      <td>2641691</td>\n",
       "      <td>6.11</td>\n",
       "      <td>250</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id               name team_code  birth_year  age  \\\n",
       "0    /players/c/claxtni01.html        Nic Claxton       BRK        1999   23   \n",
       "1    /players/s/sharpda01.html     Day'Ron Sharpe       BRK        2001   21   \n",
       "2    /players/i/irvinky01.html       Kyrie Irving       BRK        1992   30   \n",
       "3    /players/d/drumman01.html     Andre Drummond       BRK        1993   29   \n",
       "4     /players/d/dukeda01.html     David Duke Jr.       BRK        1999   23   \n",
       "..                         ...                ...       ...         ...  ...   \n",
       "503  /players/t/thomaca02.html         Cam Thomas       BRK        2001   21   \n",
       "504  /players/g/griffbl01.html      Blake Griffin       BRK        1989   33   \n",
       "505  /players/d/duranke01.html       Kevin Durant       BRK        1988   34   \n",
       "506  /players/e/edwarke02.html    Kessler Edwards       BRK        2000   22   \n",
       "507  /players/a/aldrila01.html  LaMarcus Aldridge       BRK        1985   37   \n",
       "\n",
       "    number possition  guaranteed  height  weight   exp  \n",
       "0       33         C     1782621    6.11     215   2.0  \n",
       "1       20        PF     4118400    6.11     265   0.5  \n",
       "2       11        PG    34916200    6.20     195  10.0  \n",
       "3     0, 4         C     2401537    6.10     279   9.0  \n",
       "4        6        PG           0    6.50     205   0.5  \n",
       "..     ...       ...         ...     ...     ...   ...  \n",
       "503     24        SG     4174440    6.40     210   0.5  \n",
       "504      2        PF     2641691    6.90     250  11.0  \n",
       "505      7        PF   229997220    6.10     240  13.0  \n",
       "506     14        SF        5318    6.80     215   0.5  \n",
       "507     21         C     2641691    6.11     250  15.0  \n",
       "\n",
       "[508 rows x 11 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7bca802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the current season and career results from players\n",
    "current_season_result = players[['link', 'G_2122', 'GS_2122','MP_2122', 'FG%_2122', '3P%_2122', '2P%_2122', 'eFG%_2122', 'FT%_2122', 'ORB_2122', 'DRB_2122', 'AST_2122', 'STL_2122', 'BLK_2122', 'TOV_2122', 'PF_2122', 'PTS_2122']]\n",
    "current_career_result = players[['link', 'G_career', 'GS_career','MP_career', 'FG%_career', '3P%_career', '2P%_career', 'eFG%_career', 'FT%_career', 'ORB_career', 'DRB_career', 'AST_career', 'STL_career', 'BLK_career', 'TOV_career', 'PF_career', 'PTS_career']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8ccc7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns name\n",
    "current_season_result.columns = ['id', 'G', 'GS','MP', 'FGperc', '3Pperc', '2Pperc', 'eFGperc', 'FTperc', 'ORB', 'DRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "current_career_result.columns = ['id', 'G', 'GS','MP', 'FGperc', '3Pperc', '2Pperc', 'eFGperc', 'FTperc', 'ORB', 'DRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdb01d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FGperc</th>\n",
       "      <th>3Pperc</th>\n",
       "      <th>2Pperc</th>\n",
       "      <th>eFGperc</th>\n",
       "      <th>FTperc</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/players/c/claxtni01.html</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/players/s/sharpda01.html</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.585</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/players/i/irvinky01.html</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/players/d/drumman01.html</td>\n",
       "      <td>73</td>\n",
       "      <td>36</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.524</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/players/d/dukeda01.html</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>/players/t/thomaca02.html</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>/players/g/griffbl01.html</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.724</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>/players/d/duranke01.html</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>/players/e/edwarke02.html</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/players/a/aldrila01.html</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.873</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id   G  GS    MP  FGperc  3Pperc  2Pperc  eFGperc  \\\n",
       "0    /players/c/claxtni01.html  47  19  20.7   0.674   0.000   0.674    0.674   \n",
       "1    /players/s/sharpda01.html  32   8  12.2   0.577   0.286   0.592    0.584   \n",
       "2    /players/i/irvinky01.html  29  29  37.6   0.469   0.418   0.501    0.550   \n",
       "3    /players/d/drumman01.html  73  36  19.7   0.570   0.000   0.574    0.570   \n",
       "4     /players/d/dukeda01.html  22   7  15.5   0.361   0.243   0.423    0.403   \n",
       "..                         ...  ..  ..   ...     ...     ...     ...      ...   \n",
       "503  /players/t/thomaca02.html  67   2  17.6   0.433   0.270   0.520    0.480   \n",
       "504  /players/g/griffbl01.html  56  24  17.1   0.425   0.262   0.565    0.486   \n",
       "505  /players/d/duranke01.html  55  55  37.2   0.518   0.383   0.568    0.570   \n",
       "506  /players/e/edwarke02.html  48  23  20.6   0.412   0.353   0.473    0.502   \n",
       "507  /players/a/aldrila01.html  47  12  22.3   0.550   0.304   0.578    0.566   \n",
       "\n",
       "     FTperc  ORB  DRB  AST  STL  BLK  TOV   PF   PTS  \n",
       "0     0.581  1.9  3.7  0.9  0.5  1.1  0.8  2.3   8.7  \n",
       "1     0.585  2.5  2.5  0.5  0.3  0.5  0.9  1.9   6.2  \n",
       "2     0.915  0.6  3.8  5.8  1.4  0.6  2.5  2.8  27.4  \n",
       "3     0.524  3.1  6.2  1.8  1.1  0.9  1.6  2.6   7.9  \n",
       "4     0.810  1.4  1.7  0.8  0.6  0.3  0.4  1.6   4.7  \n",
       "..      ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "503   0.829  0.2  2.2  1.2  0.5  0.1  0.8  1.0   8.5  \n",
       "504   0.724  1.1  3.0  1.9  0.5  0.3  0.6  1.7   6.4  \n",
       "505   0.910  0.5  6.9  6.4  0.9  0.9  3.5  2.1  29.9  \n",
       "506   0.842  0.9  2.7  0.6  0.6  0.5  0.9  1.8   5.9  \n",
       "507   0.873  1.6  3.9  0.9  0.3  1.0  0.9  1.7  12.9  \n",
       "\n",
       "[508 rows x 17 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_season_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "119bbefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FGperc</th>\n",
       "      <th>3Pperc</th>\n",
       "      <th>2Pperc</th>\n",
       "      <th>eFGperc</th>\n",
       "      <th>FTperc</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/players/c/claxtni01.html</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.539</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/players/s/sharpda01.html</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.585</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/players/i/irvinky01.html</td>\n",
       "      <td>611</td>\n",
       "      <td>611</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/players/d/drumman01.html</td>\n",
       "      <td>718</td>\n",
       "      <td>630</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.473</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/players/d/dukeda01.html</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>/players/t/thomaca02.html</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>/players/g/griffbl01.html</td>\n",
       "      <td>724</td>\n",
       "      <td>676</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>/players/d/duranke01.html</td>\n",
       "      <td>939</td>\n",
       "      <td>936</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>/players/e/edwarke02.html</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>/players/a/aldrila01.html</td>\n",
       "      <td>1076</td>\n",
       "      <td>997</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.813</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id     G   GS    MP  FGperc  3Pperc  2Pperc  \\\n",
       "0    /players/c/claxtni01.html    94   20  18.7   0.646   0.167   0.658   \n",
       "1    /players/s/sharpda01.html    32    8  12.2   0.577   0.286   0.592   \n",
       "2    /players/i/irvinky01.html   611  611  34.0   0.470   0.393   0.505   \n",
       "3    /players/d/drumman01.html   718  630  29.6   0.540   0.132   0.546   \n",
       "4     /players/d/dukeda01.html    22    7  15.5   0.361   0.243   0.423   \n",
       "..                         ...   ...  ...   ...     ...     ...     ...   \n",
       "503  /players/t/thomaca02.html    67    2  17.6   0.433   0.270   0.520   \n",
       "504  /players/g/griffbl01.html   724  676  32.9   0.493   0.327   0.521   \n",
       "505  /players/d/duranke01.html   939  936  36.8   0.496   0.384   0.536   \n",
       "506  /players/e/edwarke02.html    48   23  20.6   0.412   0.353   0.473   \n",
       "507  /players/a/aldrila01.html  1076  997  33.7   0.493   0.320   0.500   \n",
       "\n",
       "     eFGperc  FTperc  ORB  DRB  AST  STL  BLK  TOV   PF   PTS  \n",
       "0      0.648   0.539  1.6  3.4  0.9  0.5  1.1  0.7  2.0   7.3  \n",
       "1      0.584   0.585  2.5  2.5  0.5  0.3  0.5  0.9  1.9   6.2  \n",
       "2      0.532   0.882  0.8  3.1  5.7  1.3  0.4  2.6  2.3  23.1  \n",
       "3      0.541   0.473  4.5  8.7  1.4  1.4  1.5  2.0  3.1  13.8  \n",
       "4      0.403   0.810  1.4  1.7  0.8  0.6  0.3  0.4  1.6   4.7  \n",
       "..       ...     ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "503    0.480   0.829  0.2  2.2  1.2  0.5  0.1  0.8  1.0   8.5  \n",
       "504    0.517   0.696  2.0  6.2  4.1  0.8  0.5  2.4  2.7  19.8  \n",
       "505    0.546   0.884  0.7  6.4  4.3  1.1  1.1  3.2  1.9  27.2  \n",
       "506    0.502   0.842  0.9  2.7  0.6  0.6  0.5  0.9  1.8   5.9  \n",
       "507    0.499   0.813  2.6  5.5  1.9  0.7  1.1  1.5  2.4  19.1  \n",
       "\n",
       "[508 rows x 17 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_career_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ca30a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all the data frame into spark data frame\n",
    "teams_t_df = spark.createDataFrame(teams_t)\n",
    "players_t_df = spark.createDataFrame(players_t)\n",
    "current_season_result_df = spark.createDataFrame(current_season_result)\n",
    "current_career_result_df = spark.createDataFrame(current_career_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "07114dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- team_code: string (nullable = true)\n",
      " |-- team_name: string (nullable = true)\n",
      " |-- wins: long (nullable = true)\n",
      " |-- loss: long (nullable = true)\n",
      " |-- playoff: long (nullable = true)\n",
      " |-- is_eastern: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- team_code: string (nullable = true)\n",
      " |-- birth_year: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      " |-- possition: string (nullable = true)\n",
      " |-- guaranteed: long (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      " |-- exp: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- G: long (nullable = true)\n",
      " |-- GS: long (nullable = true)\n",
      " |-- MP: double (nullable = true)\n",
      " |-- FGperc: double (nullable = true)\n",
      " |-- 3Pperc: double (nullable = true)\n",
      " |-- 2Pperc: double (nullable = true)\n",
      " |-- eFGperc: double (nullable = true)\n",
      " |-- FTperc: double (nullable = true)\n",
      " |-- ORB: double (nullable = true)\n",
      " |-- DRB: double (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- STL: double (nullable = true)\n",
      " |-- BLK: double (nullable = true)\n",
      " |-- TOV: double (nullable = true)\n",
      " |-- PF: double (nullable = true)\n",
      " |-- PTS: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- G: long (nullable = true)\n",
      " |-- GS: long (nullable = true)\n",
      " |-- MP: double (nullable = true)\n",
      " |-- FGperc: double (nullable = true)\n",
      " |-- 3Pperc: double (nullable = true)\n",
      " |-- 2Pperc: double (nullable = true)\n",
      " |-- eFGperc: double (nullable = true)\n",
      " |-- FTperc: double (nullable = true)\n",
      " |-- ORB: double (nullable = true)\n",
      " |-- DRB: double (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- STL: double (nullable = true)\n",
      " |-- BLK: double (nullable = true)\n",
      " |-- TOV: double (nullable = true)\n",
      " |-- PF: double (nullable = true)\n",
      " |-- PTS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the schema of the data frame\n",
    "teams_t_df.printSchema()\n",
    "players_t_df.printSchema()\n",
    "current_season_result_df.printSchema()\n",
    "current_career_result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09841579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data frame into parquet format\n",
    "teams_t_df.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/teams_t.parquet\", mode = 'overwrite')\n",
    "players_t_df.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/players_t.parquet\", mode = 'overwrite')\n",
    "current_season_result_df.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/current_season_result.parquet\", mode = 'overwrite')\n",
    "current_career_result_df.write.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/current_career_result_df.parquet\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb5bbb",
   "metadata": {},
   "source": [
    "# Write into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bc13aed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "         .:::.     .::.       \n",
      "        ....yy:    .yy.       \n",
      "        :.  .yy.    y.        \n",
      "             :y:   .:         \n",
      "             .yy  .:          \n",
      "              yy..:           \n",
      "              :y:.            \n",
      "              .y.             \n",
      "             .:.              \n",
      "        ....:.                \n",
      "        :::.                  \n",
      "\u001b[0;33m\n",
      "• Project files and data should be stored in /project. This is shared among everyone\n",
      "  in the project.\n",
      "• Personal files and configuration should be stored in /home/faculty.\n",
      "• Files outside /project and /home/faculty will be lost when this server is terminated.\n",
      "• Create custom environments to setup your servers reproducibly.\n",
      "\u001b[0m\n",
      "psql:/project/MSIN0166_Data_Engineering_individual/NBA.sql:1: NOTICE:  drop cascades to 4 other objects\n",
      "DETAIL:  drop cascades to table nba.teams\n",
      "drop cascades to table nba.players\n",
      "drop cascades to table nba.current_season_result\n",
      "drop cascades to table nba.current_career_result\n",
      "DROP SCHEMA\n",
      "CREATE SCHEMA\n",
      "psql:/project/MSIN0166_Data_Engineering_individual/NBA.sql:5: NOTICE:  table \"teams\" does not exist, skipping\n",
      "DROP TABLE\n",
      "psql:/project/MSIN0166_Data_Engineering_individual/NBA.sql:6: NOTICE:  table \"players\" does not exist, skipping\n",
      "DROP TABLE\n",
      "psql:/project/MSIN0166_Data_Engineering_individual/NBA.sql:7: NOTICE:  table \"current_season_result\" does not exist, skipping\n",
      "DROP TABLE\n",
      "psql:/project/MSIN0166_Data_Engineering_individual/NBA.sql:8: NOTICE:  table \"current_career_result\" does not exist, skipping\n",
      "DROP TABLE\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n"
     ]
    }
   ],
   "source": [
    "!PGPASSWORD=qwerty123 psql -h depgdb.crhso94tou3n.eu-west-2.rds.amazonaws.com -d haiyunzou21 -U haiyunzou21 -c '\\i /project/MSIN0166_Data_Engineering_individual/NBA.sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0862cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "teams_t_df = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/teams_t.parquet\")\n",
    "players_t_df = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/players_t.parquet\")\n",
    "current_season_result_df = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/current_season_result.parquet\")\n",
    "current_career_result_df = spark.read.parquet(\"/project/MSIN0166_Data_Engineering_individual/parquet_files/current_career_result_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e500f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information for log into postgresql\n",
    "postgres_uri = \"jdbc:postgresql://depgdb.crhso94tou3n.eu-west-2.rds.amazonaws.com:5432/haiyunzou21\"\n",
    "user = \"haiyunzou21\"\n",
    "password = \"qwerty123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9fac9e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write the data into the database\n",
    "teams_t_df.write.jdbc(url=postgres_uri, table=\"NBA.teams\", mode=\"append\", properties={\"user\":user, \"password\": password, \"driver\": \"org.postgresql.Driver\" })\n",
    "players_t_df.write.jdbc(url=postgres_uri, table=\"NBA.players\", mode=\"append\", properties={\"user\":user, \"password\": password, \"driver\": \"org.postgresql.Driver\" })\n",
    "current_season_result_df.write.jdbc(url=postgres_uri, table=\"NBA.current_season_result\", mode=\"append\", properties={\"user\":user, \"password\": password, \"driver\": \"org.postgresql.Driver\" })\n",
    "current_career_result_df.write.jdbc(url=postgres_uri, table=\"NBA.current_career_result\", mode=\"append\", properties={\"user\":user, \"password\": password, \"driver\": \"org.postgresql.Driver\" })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
